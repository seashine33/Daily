# 2024年1月
## 第一周
- 1、周四前完成第二章初稿。
- 2、调代码，找到提升性能的关键部分。
### 周二：2024.1.2
------------------------------------------------------
- [CNN与GNN](https://zhuanlan.zhihu.com/p/463666907)
- [CS224W](https://web.stanford.edu/class/cs224w/index.html#content)
- 1、图神经网络出现的原因
- 2、数据结构：图
- 3、CNN与GNN的特点比较，实现方式的区别
- 4、消息传递机制
- 5、图注意力机制
  - 图注意力网络(GAT)将注意力机制引入到基于空间域的图神经网络（GNN），与基于谱域的图卷积神经网络（GCN）不同，GAT不需要使用拉普拉斯矩阵进行复杂的计算，仅是通过邻居节点的特征来更新本节点特征。GCN利用了拉普拉斯矩阵，GAT利用attention系数。一定程度上而言，GAT会更强，因为顶点特征之间的相关性被更好地融入到模型中。
------------------------------------------------------
- 总结
  - 1、把大论文的图神经网络改完了。

### 周三：2024.1.3
- 计划
  - 1、把网络模型部分改好。
- 实施
  - 1、画模型图
    - 1、Agent、Map编码
    - 2、整体预测
    - 3、分段优化
  - 2、每个模块都有一个中心
    - 1、地图编码：以车道段为中心，融入车道点
    - 2、轨迹编码：以过去每步为中心，融入每步的过去步信息、附近车道段信息、他步最后信息
    - 3、整体预测：以多模态为中心，融入本车过去时段、附近车道段信息、他车最后时段
    - 4、分段修正：以预测步为中心，融入过去步信息、附近车道段信息
    - 好我完全懂了。
  - 大论文模型部分
    - 1、高精地图编码
      - 高精度地图为车辆轨迹预测提供了充实的上下文信息，有助于提升预测的准确性和可靠性，从而强化自动驾驶系统的安全性和性能。这些地图元素通常通过点与点之间的关系来描述，例如车道线由一系列紧密连接的点表示，人行横道则以四个点来表达。车道中心线代表了车辆在行驶过程中的理想轨迹，因此通常被选为轨迹预测编码的关键对象。
      - 每条车道中心线是由若干车道中心点连接而成的折线，其
    - 2、交通参与者编码
    - 3、整体预测
    - 4、分段优化
    - 5、损失函数
- 总结
  - 输出的过程实在是太痛苦了。
  - 发现angle_between_2d_vectors函数处理的两个变量，都一样。

### 周四：2024.1.4
- 过程
  - 节点属性
    - 1、车道中心点节点
      - 维度: [N]
      - 属性: [节点坐标, 节点航向]
    - 2、车道中心线节点
      - 维度: [M]
      - 属性: [节点坐标, 节点航向]
    - 3、历史步节点属性：交通参与者每步属性
      - 维度: [A,H]
      - 属性: [节点坐标, 节点航向, 下一节点距离, 下一节点方位, 节点类型]
    - 4、多模态节点
      - 维度: [A,K]
      - 属性: [节点坐标, 节点航向]
    - 5、多模态预测步节点
      - 维度: [A,K,10]
      - 属性: [节点坐标, 节点航向]
  - 边属性: [两点间距离, 两点间方向, 两点间航向差, 边类型]
    - 地图编码
      - 车道中心点节点指向车道中心线节点的边: 
      - 车道中心线节点之间的边: 
    - 车辆历史步编码
      - 同一车辆的不同历史步节点之间的边: 
      - 车道中心线节点指向车辆历史步节点的边: 
      - 同一瞬时下不同车辆历史步之间的边: 
    - 全局预测编码
      - 车辆历史步节点指向同车多模态节点的边: 
      - 车道中心线节点指向多模态节点的边: 
      - 车辆历史步节点指向非同车多模态节点的边: 
      - 多模态节点间互相指向的边: 
    - 分段优化编码
      - 车辆历史步节点指向同车多模态预测节点的边: 
      - 多模态预测步节点互相指向的边: 
      - 
  - 邻接表: 两节点距离确定
- 总结
  - 第二章第一版总算是写出来了。

### 周五：2024.1.5
- 过程
  - 上午完善了论文，还差实验结果。
  - 下午跟陆老师讨论了我的第二章，要改的地方很多，特别是我的代码没有写出来，非常致命。我的图需要大改。
    - 0、删去图注意力网络
    - 1、体现两阶段
    - 2、体现分段
    - 3、多模态特征怎么来的
    - 4、预测时长3S，预测时长1S，
    - 5、3秒长时预测，1秒短时预测，全是预测
    - 6、多模态特征改名
    - 7、有些地方适当隐去
    - 8、看看别人的硕士论文
    - 9、段要改名，可以改成窗口，可以改成长时预测，短时预测
  - 总之需要
  - find_unused_parameters=False
- 总结
  - 重新编写q5_2_mec，该模块写的是再预测模块，假设输入的m为随机。

### 周天：2024.1.7
- 过程
  - 1、GAT聚合可以, [A,H,D]->[A,1,D]->[A,K,D]。而用GRU将[H,A,D]聚合成[1,A,D]是不是真的效果差？
  - 2、效果差的原因：
    - 有些步不存在，统一的聚合不太健康?
  - 3、把预测出的[A,K,F,D]使用GAT进行编码的可能性, [A,K,D]
- 实验：结果都为val结果
  - q3：QCNet, **baseline**
    - val_min_FDE: **1.52**, **0.949**, 
    - test_min_FDE：**1.115**
    - train_propose_loss：**0.6579**，**-0.3115**
    - train_refine_loss：**0.6396**, **-0.3269**
  - q5_0: 单次预测，**baseline**
      - 起始：**1.68**，最终：**0.981**, Dell
      - 起始：**1.523**，最终：**0.9744**，MEC
  - q5_1: 单次预测，m的初始选择
    - GRU, 加随机
      - 起始：2.03，最终：0.98, Dell
      - 起始：1.91，最终：1.014，test, 1.2775, MEC
    - GRU, 不加随机
      - 起始：5.06, Dell
      - 起始：5.31, MEC
    - 最后步, 加随机
      - 起始：3.06, Dell
    - 最后步, 不加随机
      - 起始：5.36, Dell
      - 起始：4.85, MEC
  - 旧码q5_3_mec, 分为rough和refine
    - 格式不统一
  - 旧码q5_4_mec, rough和refine合一, 初始m为GRU得到，加了随机
    - 起始：4.86，最终：1.231
  - 创建q5_6_mec, 将q5_5_med的第一次预测过程的m改成了原始代码。
    - 起始：3.58
    - 评价：走势挺好，但开始实在是太拉
  - 创建q5_7_mec, 单步一次预测，GRU编码，单步二次优化, **baseline**
    - 起始：**1.57**
  - 创建q5_8_mec，单步一次预测[A,K,F,2]，GAT编码[A,K,F,D]->[A,K,1,D], 单步二次优化。
    - 评价：写是写出来了，不过对[A,K,F,2]进行优化压力太大了。
  - 创建**q5_9_mec**, 单步一次预测取最优轨迹[A,F,2], GAT编码[A,F,D]->[A,1,D]->[A,K,D]
    - minFDE: **1.47**, 中间e35：**0.969**, 最终：**0.961**
    - test_minFDE: **1.221**, 73名
    - train_propose_loss: **0.6409**,
    - train_refine_loss: **0.6568**, 
    - 评价：相比于q5_8, 起码是可以跑的。要是效果与q5_7差不多, 那就可以用。
    - 评价：效果挺好，可以用。
    - 评价：代码写的有点问题，优化的对象不是最优轨迹，而是多模态轨迹。创建q5_10_mec，优化对象是最优轨迹。
    - 评价：与q3相比差一些。
  - 创建q5_10_mec, 优化对象是最优轨迹。
      - 起始: 4.39
      - 评价：基于最优轨迹进行优化结果太差。
## 第二周
### 周一：2024.1.8
- 过程
  - 创建q6_1, 基于q5_8_mec, 单步一次预测[A,K,F,2]，GAT分段编码3*[A,K,10,D]->[A,K,1,D]->[A,K,D]，多步二次优化。
    - 起始：
    - 评价：batch为1, 9G多显存，那这也是一版废代码，有的场景A大，需要的显存就是等比例放大。
  - 创建q6_2, 基于q6_1, 之前A,K算一个场景，现在分为K个场景
    - 起始：1.610
    - 评价：batch为8, 差不多把24G吃满了，勉强可以跑。不过一个batch要4个小时。
    - 评价：帮助不大
    - **解决方案**：循环，[A,K,S,D] -> K*[A,S,D], 分六次计算。有点异想天开，边是完整的。
  - 创建q6_3, 基于q6_2, 二次预测不分段
    - 起始：
    - 评价: 
  - 创建q6_4, 基于q5_9_mec, 取最优轨迹[A,F,2], GAT分段编码[A,S,D]->[A,1,D]->[A,K,D]
    - 起始：1.770
    - 评价：第一次实验的优化目标写错了。改了一下接着跑。
    - 评价：不怎么样。
- 总结
  - q6_2：验证基于多模态的二次分段预测是否有优越性。
  - q5_9_mec：验证了使用GAT对一次预测最优轨迹[A,F,2]再编码，比用GRU对一次预测多模态轨迹[A,K,F,2]再编码的效果要好。
  - 按现有情况看，绝对是沿着q5_9_mec继续做下去比较好。
  - [x] 突然发现一个华点，我基于最优一次轨迹训练出来的优化值，是基于**多模态一次轨迹**的优化值。我真的笑了，我得做个实验，看是基于**最优一次轨迹**的多模态好，还是**多模态一次轨迹**好。q6_4确实是基于**最优一次轨迹**来的。创建q5_10_mec。

### 周二：2024.1.9
- 过程
  - 看其他硕士论文第二部分
  - 宁
    - 介绍了Frenet坐标系与笛卡尔坐标系间的转换
    - 轨迹生成
    - 时空走廊法进行碰撞检测
    - 多代价函数评估剩余轨迹
  - 彭
    - 车辆碰撞风险影响因素分析(行车风险来源)
    - 行车风险场模型(场值设计)
    - 行车风险评估方法(碰撞判定方法)
  - 创建**q6_5**, 基于q6_4, 将优化目标改为第一次预测的多模态轨迹。
    - 起始：**1.440**, 最终：
    - 实验二：1.490
    - 评价：woc, 离谱了xdm, 那岂不是说，我有第一个结果了。
    - 描述：一次预测为以random为m的完整预测，二次为以最优一次结果为m的完整预测。
    - 下一步：历史轨迹再编码。
    - 评价：最后的结果好像还是不如q5_9_mec，这说明分段的优势并没有体现。
    - 评价：跟q5_9_mec的refine_loss一样。
  - 创建q6_6, 基于q6_4, 二次预测每步预测的m仅为10步未来特征编码。优化目标仍为第一次预测最优轨迹。
    - 起始：3.690
    - 评价：好好好，果然差得离谱。
  - 给模型各模块起名字
    - 1、地图编码模块, center: 每一坐标点，每一车道线
      - point embed: [N,D]
      - line embed: [M,D]
      - point to line：车道点聚合, [N,D]
      - line to line：车道线间聚合, [M,D]
    - 2、历史轨迹编码模块, center: 每一坐标点
      - history embed：[A,H,D]
      - for i in range(num_layers)
        - agent based:[A,H,D]->[A,H,D]
        - line to history: [M,H,D]->[A,H,D]
        - time based to ours: [A,H,D]->[A,H,D]
    - 3、未来轨迹编码模块, center: 每一坐标点
      - future embed：[A,K,F,2]->[A,F,2]->[A,F,D]
      - for i in range(num_layers)
        - agent based to future：[A,F,D]->[A,F,D]
        - line to future: [M,D]->[A,F,D]
        - time based to future：[A,F,D]->[A,F,D]
        - future to one: [A,F,D]->[A,1,D]
      - repeat：[A,1,D]->[A,K,D]
    - 4、可变窗口预测模块, center: 最后已知位置
      - mode：[A,K,D]
      - for i in range(num_layers)
        - history to mode: 时间聚合模块, [A,F,D]->[A,1,D]->[A,K,D]
        - line to mode：地图聚合模块, [M,K,D]->[A,K,D]
        - last history to mode：最后历史特征, ([A,1,D]->[A,K,D])->[A,K,D]
      - mode to mode： [A,K,D]
      - MLP：[A,K,F,2]
- 总结
  - 一开始写大论文就困得受不了。
  - 我应该是有点发烧了。

### 周三：2024.1.10
- 过程
  - 创建q6_7, 基于q6_4, 二次预测的m与a相加的过程复杂化，MLP。优化目标为第一次预测多模态轨迹。
    - 起始：
    - 评价：
  - 创建q7_3_mec, 基于q5_0_mec, 把history to one 的过程放到Agent编码当中了，然后decoder的time to mode删去。
    - 起始：1.7
    - 评价：运行速度挺快，二十分钟一轮。
    - 评价：比1.523确实差了。
  - 创建q7_4_mec, 基于q7_3_mec, 把random在agent encode阶段融入。
    - 起始：1.673
    - 评价：比q7_3_mec强了一点
  - 新建MEC下的test预处理集，这里的预处理全是初始的。
  - 创建q7_5_mec, 基于q7_4_mec, m与x_a的属性交换
    - 起始：2.024
    - 评价：很差
  - 创建q6_7, 基于q6_5, [A,S,D]跟[A,H,D]没有交互，插到x_f生成的过程中了。
    - 起始: 1.531
    - 分析：编码目标是[A,H,D]和[A,K,D], [A,S,D]也就是个中间变量。
      - 要不要在将[A,S,D]和[M,S,D]灌入[A,S,D]的同时，将[A,S,D]灌入[A,H,D]
    - 评价: 其实不对，应该是窗口滑动后才把x_f学入x_a
- 总结
  - 看了比QCNet更优结果的图，有一个cat([A,D],[M,D])=[A+M,D]的过程，挺有意思的，我能不能像这样也创出一个新的格式呢？
  - 现在是中午12：52，好像又开始发烧了，回去躺躺。
  - 把q5_9的test结果算一下，代码调了半天
  - **idea**: 我对future进行了分段编码，得到[A,S,D], 这个[A,S,D]跟[A,H,D]没有交互。
  - **实验**，q6_7_mec的两词预测的self.mode_emb.weight都是一个，换成两个

### 周四：2024.1.11
- 过程
- 总结
  - 花了一上午确定了一下要投的期刊，22号截止，起码要写8页。
  - 后面我就不一门心思跑实验了，今天的任务就是把大论文的第二章改好。也就是把论文总体框架总结出来。（争取吧）
  - 然后玩了一天。

### 周五：2024.1.12
- 过程
- 总结
  - 上午把模型图重新排列了一下，乍一看我的模型，突然觉得已经和QCNet区别很大了。代码部分，只要分段优化结果好于整体优化，我的代码也没有问题了。
  - 然后的任务就是造词，也就是把模型名字起一下。
  - 把每一模块功能加上去就不想干啦，感觉写的七七八八。
  - 可以一边写小论文，一遍把实验结果弄出来了。

### 周六：2024.1.14
- 总结
  - 写英文论文，完全不会写啊。
  - 使用长窗口做预测，long-window based prediction
  - 使用短窗口做优化

## 第三周
### 周四：2024.1.18
- 总结
  - 最近几天都在写EI。
  - 给老师看了一下，说让我照着模板改改，提取一下创新点，明天给她看。
  - 当天晚上吃了个饭就没再工作了。

### 周五：2024.1.19
- 总结
  - 早上是来了，但也确实半天都无法静下来开始写。十分抗拒。

## 第四周
### 周三：2024.1.24
- 总结
  - 周天把EI投了，然后就玩了两天，现在想继续写论文，但提不起精神
  - 继续玩的话不太好，应该做点别的
  - 好嘞，还是玩了一天，玩中共开作弊码速通全国，然后造船打海战，登陆日本结束中日战争，然后研究了一下占领区和傀儡国的互换。
  - 打到大概四点，吃了个午饭，接着杀戮尖塔，通了大概四次吧，算是玩好了。
### 周五：2024.1.26
- 总结
  - 昨天中午起，然后开始写了，算是很有工作状态
  - 今天中午起，接着美咪，继续改大论文。
## 第五周

### 饥荒服务器
- ip
  - master: 120.55.69.84
  - cave: 121.43.105.129
- 教程
  - [事无巨细的Steam饥荒联机云服搭建教程](https://blog.csdn.net/Hydius/article/details/106121931)
  - [SteamCMD开发者社区](https://developer.valvesoftware.com/wiki/SteamCMD)
  - [Steam版饥荒双专用服务器搭建教程](https://blog.csdn.net/XUdashi/article/details/118695063)
- 流程
  - root用户
    - adduser steam
    - usermod -aG sudo steam
    - su steam
  - steam用户
    - sudo apt-get update
    - sudo apt-get upgrade
    - sudo apt-get install lib32gcc-s1
    - sudo add-apt-repository multiverse
    - sudo dpkg --add-architecture i386
    - sudo apt install libstdc++6 libgcc1 libcurl4-gnutls-dev:i386 lib32z1
      - cd /usr/lib/
      - sudo ln -s libcurl.so.4 libcurl-gnutls.so.4
    - 报libstdc++.so.6的错
      - sudo apt-get install libstdc++6 
      - sudo apt-get install lib32stdc++6
    - sudo apt-get install screen
    - sudo apt install unzip
    - sudo apt update
    - mkdir steamcmd
    - cd steamcmd
    - wget -P ~/steamcmd https://steamcdn-a.akamaihd.net/client/installer/steamcmd_linux.tar.gz
    - tar -xvzf steamcmd_linux.tar.gz
    - ./steamcmd.sh
      - force_install_dir /home/qh/dst
      - login anonymous
      - app_update 343050 validate
      - exit
  - klei开服
    - https://accounts.klei.com/login
    - 获取token
  - 存档
    - 服务器标签写入cluster_token.txt
- 启动
  - ./dontstarve_dedicated_server_nullrenderer -console -cluster "Cluster_1"
  - ./dontstarve_dedicated_server_nullrenderer -console -cluster "Cluster_1" -shard Master
  - ./dontstarve_dedicated_server_nullrenderer -console -cluster "Cluster_1" -shard Caves
- 双服务器
  - 开端口不是命令行开，是云服务器控制台的安全组里面开，协议类型是UDP。
- 添加mod
  - 服务器目录mods文件夹下/dedicated_server_mods_setup.lua

### 周三
- 总结
  - 今天把服务器弄好了，显示开服，然后是mod，再是双服务器。
  - 今天弄双服务器，开一个端口，卡了三四个小时。
  - 现在是四点一刻，等外卖中。。。
  - 把大论文1.3的模型部分写完了。
  - 明天的任务是把图全部改好，然后实验结果。