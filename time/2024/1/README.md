# 2024年1月
## 第一周
- 1、周四前完成第二章初稿。
- 2、调代码，找到提升性能的关键部分。
### 周二：2024.1.2
------------------------------------------------------
- [CNN与GNN](https://zhuanlan.zhihu.com/p/463666907)
- [CS224W](https://web.stanford.edu/class/cs224w/index.html#content)
- 1、图神经网络出现的原因
- 2、数据结构：图
- 3、CNN与GNN的特点比较，实现方式的区别
- 4、消息传递机制
- 5、图注意力机制
  - 图注意力网络(GAT)将注意力机制引入到基于空间域的图神经网络（GNN），与基于谱域的图卷积神经网络（GCN）不同，GAT不需要使用拉普拉斯矩阵进行复杂的计算，仅是通过邻居节点的特征来更新本节点特征。GCN利用了拉普拉斯矩阵，GAT利用attention系数。一定程度上而言，GAT会更强，因为顶点特征之间的相关性被更好地融入到模型中。
------------------------------------------------------
- 总结
  - 1、把图神经网络改完了。

### 周三：2024.1.3
- 计划
  - 1、把网络模型部分改好。
