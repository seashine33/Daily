# 题目
VaLW: Multi-Centric Motion Forecasting with Variable Length Window. 具有可变大小窗口的多中心运动预测。

## 0. 摘要
车辆轨迹预测是实现自动驾驶的重要一环，其可以直接展现他车的运动意图。提出一种多中心的场景编码模块，基于多种半径确定各交通节点间的连接关系，并使用cross-attention让各节点特征相互学习，以实现对场景的深度学习。此外，在轨迹预测时，随着预测时长的增长，预测精度会迅速下降。我们提出一种可变窗口长度的结构，对长窗口预测出的多模态结果进行短窗口优化，以在模型大小与预测精度之间取得平衡。结合这两点，我们提出了一种高预测精度的轨迹预测网络（VaLW），该网络在Argoverse运动预测数据集中取得了优秀的成绩。【算法特点，创新，解决什么问题】
关键字：Motion Forecasting, Autonomous Driving, multimodal prediction, HD Map

创新点：多中心的编码模块。具有优化结构的解码模块。
## 1. Introduction
1. 对于智能驾驶汽车，提前预知周边车辆的意图甚至是未来几秒行动轨迹，对降低行驶过程中的风险将有相当大的帮助。然而运动预测是极具挑战性的，其原因是：1、输入是异构且多个来源的，2、预测结果有相当多种可能都符合实际，需要进行多模态预测。3、随着预测时长的增长，预测精度迅速下降。
2. 运动预测模型通常从Agent历史轨迹与高精地图信息中得到场景信息并对目标Agent进行预测。这些场景信息间存在复杂的语义关系，如Agent之间的关系，Agent与地图之间的关系，地图元素之间的关系。在先前的方法中通常对不同类型的数据使用同样复杂的模型进行建模。例如在LaneGCN中，使用四个子网络分别实现Agent到Agent，Agent到Map，Map到Agent，Map到MAP的交互。在mmTransformer中应用通用Transformer架构来将Agent历史轨迹、高精地图和连接关系进行融合。
3. 由于代理意图的不确定性，运动预测任务中输出的结果是多模态的。生成多模态的方法一般是将最后的解码模块，如MLP的输出维度按模态的数量进行扩充，如LaneGCN，这种方法的模态之间的差异性不强。另一种方法是场景编码后，不以轨迹作为预测目标，而是以端点。如在TNT中，会生成远远大于所需模态的目标点，并对每一目标点进行评分，最后选取评分高的几个点进行轨迹补全。在HOME中，使用热力图作为预测结果，再从最可能的目的区域选取目标点，这类方法的预测精度不够优秀。
4. 根据这些观察结果，我们提出了VaLW：一种多中心的具有可变大小窗口的预测模型。该模型以多中心的结构对异构输入进行编码：首先编码模块对车道点进行聚合，得到车道线，以车道线为中心进行地图元素编码，其次对每一Agnet步为中心进行编码，然后以每一Agent的历史步为中心对附近车道线进行学习，以Agent为中心进行时间维度的学习，以每一瞬时为中心对附近车辆信息进行学习。解码阶段使用可变长窗口将解码器分为两部分，第一部分使用长窗口预测出多模态的完整预测轨迹及每一模态结果的评分，从每一Agent的多模态预测结果中选出最优轨迹，对时间维度进行划分，接着使用短窗口对短区间最优轨迹进行优化，最终拼接得到完整的优化结果。
5. 我们主要的贡献如下：1、提出了一种多中心的编码方案，对异构输入进行编码，得到蕴含丰富信息的场景上下文；2、提出一种两阶段的解码模块，首先使用长窗口进行多模态轨迹预测后，使用短窗口对最优轨迹进行精炼。3、使用Argoverse 1 运动预测数据集对模型效果进行评估，与流行的基准相比取得了优秀的结果。
## 2. Related Work
场景上下文编码。基于对场景信息的表达方式，运动预测的方法可以分为光栅化和矢量化两种类型。光栅化的方法将Agent的轨迹与高精地图信息使用数字化的像素图像表达，并使用基于图像的网络（如CNN等）对场景上下文进行编码。矢量化方法以矢量序列的形式描述Agent和MAP的状态。除此之外，对于Agent编码的参考坐标系，方法分为以场景为中心和以Agent为中心。以场景为中心表示场景中所有的代理都共享同一坐标系，这有利于提高计算效率；而以Agent为中心则是每一Agent的坐标系都单独确定，有利于提高预测精度。
强化多模态输出。关于多模态预测方面的研究相当广泛。首先是基于规划的方法，根据车道情况和运动学约束生成大量可行的轨迹作为候选轨迹。在mmTransformer中使用基于区域的训练方案，在手动定义的区域中查找预测目标，以丰富输出。TNT[30]和DenseTNT[7]分别依靠对稀疏和密集预测目标进行采样来实现对所有可行预测结果进行讨论。我们方法是通过解码过程中将解码特征按多模态的数量进行扩充，期望每一Agent的不同模态在解码过程中会关注场景上下文的不同方面。
## 3. Approach
图1展示了VaLW的总体框架，其使用多中心的方法将异构输入编码为蕴含丰富信息的场景上下文，并基于长窗口的预测模块生成多模态轨迹和评分，然后选择最优评分轨迹进行分割，接着按顺序使用基于长窗口的优化模块得到优化值，最终对优化结果进行拼接。
### 1. Input Representation
   - VaLW的输入包括Agent History Trajectory和Lane Point. 不同输入的详细介绍如下：
   - Agent History State are represented as a tensor [A,H,D_A]。A代表预测场景中Traffic Agent的数量。H代表历史步的数量, 并非所有的Traffic Agent都具有完整的H步历史轨迹，为了模型对所有有效Traffic Agent进行预测，将不完整的历史轨迹扩充至H，并将不存在的历史步进行标记。D_A表示Agent的状态维度, Agent的瞬时状态包括坐标，速度大小及其方向，航向角等，为了在预测过程中更好的学习车辆的移动情况，VaLW对输入进行了一定的变换，如将每点坐标转化为到下点的位移向量。
   - Lane Point 可用向量表示为[P,D_P]。其中P表示场景中所有车道点的数量，为了减小数据处理与学习的负担，将一定数量相互临近的Lane Point按顺序聚合成Lane line。D_P表示车道点的状态维度，每一车道点的状态包括坐标和方向等。选择车道线的初始Point的state作为Lane line的代表state，除此之外，Line还有一些辅助信息，如车道是否转向、车道是否有交通管制，是否为交叉路口等。Lane line用向量表示为[L,D_L]。

### 2. Multi-Centric scene encoder, 多中心的场景上下文
   为了让异构输入间更好的交互融合，编码出蕴含信息更丰富的特征，本文首先使用傅里叶嵌入将输入统一编码到相同的隐藏层维数上。接着使用基于不同中心的图注意力层来将不同类型的输入、输入的不同维度之间相互关联，以让每一节点都包含丰富的场景上下文。
   1. line-Centric map Encoder. 
      1. 我们使用傅里叶嵌入将Lane point和Lane Line的状态编码到特定维度。接着因为Lane Line由Lane Point汇聚而来，故让每一Lane Point的特征也都汇聚到其对应的的Lane line的特征中。接着基于距离建立Lane Line间的邻接关系，让Lane Line关注其附近Lane Line的特征，丰富道路信息上下文。
   2. history-point Centric Encoder. 
      1. 使用傅里叶嵌入将每一Agent的每步状态都编码到特定维度。本模块共使用了三种不同中心的的图注意力，其中第一种为让每一历史步特征去关注附近的车道线特征，让每一历史步捕捉完整的空间线索。
   3. Agent-Centric Attention. 
      1. 第二种图注意力针对同一Agent的不同历史步特征，使其相互学习。由于时间的一维性，每一历史步特征只能学习对于其来说的过去特征，而不能提前知道确切的未来信息。过于久远的状态对于预测行为没有意义，故基于时间差距确认每步特征学习的历史范围。
   4. time-Centric Attention. 
      1. 在第三种图注意力种我们让属于同一瞬时下的Agent步基于距离的远近相互学习。轨迹预测中最难解决的问题之一就是学习车辆间复杂的交互，判断每辆车在各种场景下的反应。本模块对每一瞬时场景进行讨论，让同一瞬时下相邻的车辆特征进行关注，以捕捉车辆间的交互细节。

### 3. Trajectory decoding with Variable length window, 具有变长窗口的轨迹解码。
   预测精度会随着预测时长的增加而急剧下滑。为了缓解这个现象，对长窗口预测出的完整预测轨迹进行划分后编码，接着按时间顺序分别使用短窗口进行优化，最后对优化结果进行拼接。
   1. multimodal-Centric query. 
      1. 为了提升模型的multimodal性能，可学习query的维度基于Agent数量和多模态数量，每一Agent都可分得多模态数量的query，这些可学习query在解码过程会中使用cross-attention学习编码信息。这样设计的目的是将预测模块常使用的以交通参与者为解码单元，转化为以多模态交通参与者，让每个模态在整个解码过程中平等地学习编码特征，自由地关注不同细节，提升模型的多模态性能。
   2. long-window based prediction. 
      1. 该模块使用完整预测时长作为长窗口的长度，选择每一Agent的最后已知状态作为代表状态与相邻场景进行邻接关系的确定，使用cross-attention让可学习query学习编码好的场景信息。接着使用自注意力让属于同一Agent的多模态特征间相互学习。最后使用MLP解码出多模态的完整预测长度的预测轨迹及其评分。
   3. future-point Centric query. 
      1. 根据long-window based prediction的结果，选出评分最高的模态结果作为优化目标。对最优预测结果按时间维度平均划分为N个区间，对每一区间的预测轨迹进行编码，编码过程与历史步编码类似，对每一未来点附近的车道线特征，过去历史步特征及对应瞬时下的临近他车特征进行学习。最终得到用于短窗口优化的短窗口query。
   4. Short-window based refinement. 
      1. 本模块使用与N个短区间等长的短窗口进行轨迹精炼。不同短窗口query按时间顺序进入，每优化完一个短窗口query，窗口就滑向后一短区间继续优化直到全部轨迹优化完成。短窗口query学习环境信息的过程与长窗口预测模块类似，输出的结果为最优轨迹的修正值。最终对不同区间的优化结果进行拼接，得到完整优化轨迹。
### 4. Training Objective
   1. 我们对长窗口预测模块结果与短窗口优化模块结果都使用基于拉普拉斯分布的负对数似然函数作为回归损失进行了监督。
   2. 公式（1）
   3. 其中p_i表示真值轨迹，u_i表示预测轨迹，b_i表示预测尺度
   4. Where pi represents the true trajectory, ui represents the predicted trajectory, and bi represents the predicted scale.
   5. 为了确保从多模态结果中评选出最优的预测轨迹，对评分结果也设置了使用负对数似然函数表达的分类损失函数进行了监督。
   6. 使用负对数似然函数表达分类损失L_cls，监督模型预测出的段轨迹评分。
   7. 总损失值的设计如下。

## 4. Experiments
   1. 数据集与评价指标：
      1. 数据集：
         1. 我们使用Argoverse 1 Motion Forecasting数据集验证我们方法的有效性。该数据集分为三个集合共324557个场景，每个场景对应一个CSV文件。其中训练集205942个场景，用于训练预测模型；测试集39472个场景，用于在训练过程中查看训练结果，不参与训练；评估集78143个场景，用于训练完成后用于评估模型结果。训练集与测试集的场景时长为5秒，而验证集时长仅2秒，故该数据集的任务即为基于历史的2秒轨迹预测未来3秒轨迹。每个场景都以2D鸟瞰图坐标的形式对每个跟踪对象以10Hz采样。
      2. 评价指标：我们沿用了Argoverse Motion Forecasting Competition的Evaluation Criteria，
         1. minFDEk: The L2 distance between the endpoint of the best predicted result among k modes and the ground truth.
         2. minADEk: The average L2 distance between the best predicted result among k modes and the ground truth.
         3. MRk: The proportion of scenes where the result of minFDEk exceeds the 2m threshold.
         4. brier-minFDEk: The calculation process of minFDEk adds (1.0 − p)^2, where p is the probability of the best prediction result.
   2. 实验结果: 
      1. 我们将VaLW与其他在Argoverse 1 Motion Forecasting leadboard上发布的方法进行公平地比较，包括LaneGCN，mmTransformer，DenseTNT，TPCN，SceneTransformer，HOME+GOHOME, 结果如表1所示。VaLW，我们提出的运动预测模型，成功地在预测性能和模型参数之间取得了完美的平衡，实现了最佳性能。在Argoverse 1 Motion Forecasting数据集中，VaLW展现了卓越的运动预测能力。具体而言，VaLW实现了1.85的brier-minFDE，超过了其他列出的方法，包括先进的HOME+GOHOME。总体而言，VaLW是一种非常有前途和适用于各种现实场景的高级轨迹图预测网络。
   3. 消融实验
      1. 评价：为了证明所提出的VaLW的有效性，我们在Argoverse Motion Forecasting数据集上进行了消融实验，以验证不同模块的效果。首先，我们为消融实验设计了一个基线网络，移除SWR部分。随后，我们将具有不同窗口长度的SWR添加到基线网络中：（1）基线+SWR(L=3s)：与基线相比，将优化窗口为3秒的SWR模块加入模型中，brier-minFDE提高了0.05。（2） 基线+SWR(L=1.5s)：与基线相比，将优化窗口为1.5秒的SWR模块加入模型中，brier-minFDE降低了0.09。（3） 基线+SWR(L=1s)：将优化窗口为1秒的SWR模块加入模型中，与基线相比，brier-minFDE降低了0.12。（4） 基线+SWR(L=0.6s)：将优化窗口为0.6秒的SWR模块加入模型中，与基线相比，brier-minFDE降低了0.12。这证实了轨迹优化模块的有效性，且说明在一定程度内缩小预测窗口，可以得到更为优秀的优化结果。
      2. 可视化：为了更直观地了解SWR对预测结果的提升，图2对预测结果进行了展示。其中红线表示历史轨迹，绿线表示ground truth，蓝色虚线表示多模态的预测轨迹。左图为无SWR模块的预测结果，右图为带的SWR模块(L=1s)的预测结果。可以明显的观察到经过优化后，各模态的预测结果更贴近实际情况。

## 5. Conclution
   我们提出了一种窗口长度可变的多中心的轨迹预测方法VaLW。在编码部分，该网络能使用多中心的方法对异构输入进行学习，在复杂的驾驶环境中学习车辆之间的潜在交互。此外，基于可变长窗口的解码器，对长窗口预测出的结果进行短窗口优化，该结构能显著的提升模型的预测性能，缓解随着预测时长的增长，预测精度快速下降的现象。我们提出的VaLW在Argoverse 1 运动预测数据集上展示了出色的结果。