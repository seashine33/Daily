# 2023.12.1 周五
- [x] 把相关超参数全部调成初始值，再做实验，看是不是过拟合，不管是什么原因的过拟合。
> 我拿初始的epoch 1进行test，结果为11多，看来还是模型代码的问题。


- [x] 除了调参以外，还可以把计算loss的过程改为把预测值旋转平移到世界坐标系，与真值求欧氏距离。  
> 不肯是旋转平移的问题了，因为我拿test代码跑了val的，没有问题，直接看散点图都没问题。


- [ ] Risk Assessment 帖子推荐的第一篇论文是讲AV的风险评估(RA)的，重点看看。
> 风险评估方法

- [x] 昨晚突然想出来的法子，test集没有真值，我拿val集走一遍test代码，拿结果对比一下。
> 为了方便，首先把test_obs和val文件名相互替换。  
> test代码好像不管其他的数据，直接拉了val前1000数据过来当test的some，把结果存到test的some_result里面，最后发现，预测效果很好，效果好不是假的。  
> 那就真见鬼了，除非我拿val集训练了，不然这也太怪了。又看了一下，val代码连loss都没有输出，怎么可能训练了。  
> 那，到底是为什么呢？  
> 我发现一个特征，val数据跑出来的数据，Excel可以一下子识别出来散点图，但test就识别不出来，反正就是val什么都是好的，test啥啥不行，**是不是test的编码有问题啊**，没有兼容。  
> 或者说，完整轨迹就是OK的，不完整轨迹就是有问题。

- [x] test数据的编码过程有没有问题？
> test又分了几个文件夹  
> some_val, some_test 分别存了val和test前一千个场景  
> some_qcnet_val, some_qcnet_test分别是其编码信息，  
> some_result_val, some_result_test分别存了预测结果。  
>
> 然后就是看代码了，后面再看吧。
>
> 发现问题了，见 12.4 part 1。

周五下午两点半，已经不想学了。验证上面那一点竟然弄了四个小时。  
我竟然连菜都忘了收？  
一来就验证数据去了。

# 2023.12.4 周一
## 1、QCNet代码test部分找到问题所在了
> 首先是看test数据集，因为不存在未来数据，看是否对训练过程有影响  
> 道路编码，以AV为中心，考虑半径怎么才100？  
> 果然，解码的时候用到了'predict_mask'，我看这一步的备注是“只有存在未来步才预测”，好家伙。  
> 把预处理的部分改了一下，再跑一遍试试。【重大进步】  
> FDE 1.20，我总算是，四个月，总算是找到问题所在了。  
> 然后这个数据我是拿QCNet的原始超参数进行的test，与训练过程的test不同，后面我要进行多次实验。

- [ ] 超参数调整，test过程的超参数设置对结果的影响如何。
> QCNet原始超参数, q3, version_5, epoch_54, FDE 1.20, bFDE：1.899  
> 新参数, q3, version_5, epoch_54, 这个是0.000001的区别
> 
> QCNet原始超参数，version_1，epoch_43，FDE 1.22，bFDE：1.915  
> 新参数，version_1，epoch_43, ？竟然结果一样, 哦，有0.0000001的区别
> 在MEC上处理。
>
> 所以结论是，这些半径什么的超参数不重要。

## 2、写场景介绍，画场景图。
> 打算看看论文，看不下去。  
> 打打游戏缓缓。   

> 结果拉着开会，要写场景的文档。  
> 写差不多了，晚上又得开会  
> 讨论场景为交叉路口，场景参与方有若干行人与车辆；车辆在机动车道上行驶，行人在人行横道上行走。路测端传感器实时识别追踪并记录下场景中各个参与者的位置，作为轨迹预测模块使用的历史轨迹。轨迹预测模块基于场景中所有参与者的历史轨迹，结合场景地图数据，进行预测时长为5秒的多模态预测。碰撞风险评估模块基于多模态未来轨迹，评判场景中各参与者的碰撞风险。对碰撞风险过高的场景参与者进行预警，如行人通过APP得到预警，使其注意周边车辆。  
> 图的话，可以用一个在线画图网站：  
> https://products.aspose.app/diagram/zh-cn/editor  

> 代码终于可以跑啦，轻松多了。  
> 发现QCNet初始数据可以以batch_size 16跑，可以，理论上四天多就可以跑完。  

# 2023.12.5 周二
## 1、QCNet 实验
> 跑实验，显存占用率太高了只剩二十几兆。  
> 玩了会MEC，准备把代码备份一下。  
> 把所有的结果都放到q1里面去了，减小q3的大小。  
> 把数据备份到U盘了，然后拷了一份到MEC上，给MEC装上QCNet的环境。  
> 现在正在跑的代码大概1.5h一个epoch，4天跑完，这4天把已有的模型测一下。  
> 每次配环境的时候，需要把map_file移到环境文件夹下，今天发现原来是初始化am时没有指定文件夹。  

> 新建了q7，用来实现经过几个月沉淀的方案。  
> 首先把代码整理了一下，主要删除了一些用于av1与av2兼容的代码，主要是head。  
> 

## 2、Risk Assessment方法
> [碰撞评估综述](/note/Risk%20Assessment/node/Risk_Assessment_Methodologies_for_Autonomous_Driving_A_Survey.md)


# 2023.12.6 周三
> 睡到中午起  
> 吃饭接着睡午觉  
> 三点起来去东湖玩，七个人  
> 吃完饭打牌  
> 一点到寝室睡觉  

# 2023.12.7 周四
## 1、QCNet实验
> 感觉用初始参数效果会更好啊。
> 38个epoch就到了自己设的参数了。

## 2、Risk Assessment方法
> [碰撞评估综述](/note/Risk%20Assessment/node/Risk_Assessment_Methodologies_for_Autonomous_Driving_A_Survey.md)

## 3、毕业论文
> 了解了一下，这TM才是最重要的部分，甚至看什么综述都属于是非常浪费时间   
> 开始急躁了，在实验室根本不能得到安宁了  
> 后面得调作息 + 去图书馆了  

## 4、修改QCNet代码
> 论文看不进去，想该改改代码。
> 先不上手改吧，先把结构图画出来。


- [ ] 实验：QCNet去掉第二次解码，结果是多少？
> 结果
> 
- [ ] 改代码
> 1、QCNet的m是由(6,128)repeat出来的，而我的是(A,128)repeat出来的，检查保证统一，再编码的部分，m的维度也要实验一下，这大概就能弄懂为什么会有transpose了吧  
> 2、QCNet的refine是初始值的修正值，也就是refine+rough才是第二次预测的结果。相应的scale也有区别，这要做实验确认哪个效果好。

闹钟定了，计划下了，感叹完了  
然后发出脱离互联网能不能活的疑惑  

# 2023.12.8 周五
## 1、日结
> 早上确实是八点半起来的，但昨晚三点还没睡着  
> 起来还算是清醒，但肯定要睡午觉  
> 到实验室九点，刚好开始上班

## 2、QCNet
> 跑到epoch=49了，相比昨天下午又有轻微的增长

## 3、毕业论文
- 1、粗略读彭赛骞论文
  - 第二章主要介绍了Argoverse数据集，还有地图数据格式，图神经网络。
  - 第三章讲了基于目标的轨迹预测流程
  - 第四章碰撞风险评估，就不太熟悉了。
- 2、重读《QCNet》
  - 终于读懂了以代理（Agent）为中心，以查询（query）为中心是什么意思。
  - 之前使用地图数据：将所有路点基于车辆进行旋转平移，再编码。
  - 现在使用地图数据：将所有polygon（polygon初始waypoint位置）与waypoint（waypoint间的距离）的关系建立好，然后都embedded到128维，然后将waypoint间的距离编码到polygon里面，再polygon相互编码。
  - 以解码策略难以捕捉多模态为理由，进行无锚、有锚预测的区分。
  - 图一说明了其对每步每帧都进行了编码。
  - 观察窗口，我大概明白他的意思，也就是以代理为中心的情况下，历史时间变化了，对应的所有代理也要重新编码。
- 3、[注意力机制综述](https://zhuanlan.zhihu.com/p/631398525)
  - 自注意力机制
    - 首先对输入x进行embedding，得到a。
      - 假设映射到128维
    - a会乘三个矩阵w(qkv)，得到qkv，这三个矩阵在整个过程中共享
    - q（query）的含义一般解释是用来与其他单词进行匹配，或者说计算当前单词与其他单词之间的关系。
    - k（key）用来与q进行匹配，或者说单词的关键信息。
    - 若要计算a1与a1234之间的关系，需要q1，和k1234进行匹配计算，得到α1234
      - α1为两128维向量点乘后除根号128，为一个float型
    - 对α1234进行softmax操作，得到~α1234。
      - ~α1234，4个大于0的float型和为1
    - v（value）的含义主要表示当前单词的重要信息。
    - v1234与~a1234按序号相乘后求和，得到b1。
      - b1根据相似性包含了a1234的信息，为128维向量。
    - ![tup](/time/2023/12/img/屏幕截图%202023-12-08%20114411.png)
  - 多头自注意力机制
    - 多头注意力机制是在自注意力机制的基础上发展起来的，是自注意力机制的变体,旨在增强模型的表达能力和泛化能力。它通过使用多个独立的注意力头，分别计算注意力权重，并将它们的结果进行拼接或加权求和，从而获得更丰富的表示。
    - 看代码会简单一些
  - 通道注意力机制
    - 图像数据有多通道，例如RGB三通道【这里的理解很主观】，其是对每个通道求一个标量，用来学习每个通道的权重。
    - [ ] 可以类比，比如对每个Agent求一个权重。
  - 空间注意力机制
    - 空间注意力机制和通道注意力机制具有异曲同工之妙，通道注意力机制旨在捕捉通道的重要性的程度，空间注意力机制旨在通过引入注意力模块，使模型能够自适应地学习不同区域的注意力权重。这样，模型可以更加关注重要的图像区域，而忽略不重要的区域。
- 4、[深入理解图注意力机制(Graph Attention Network)](https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/105548217)
  - 作为一种代表性的图卷积网络，Graph Attention Network (GAT) 引入了注意力机制来实现更好的邻居聚合。通过学习邻居的权重，GAT 可以实现对邻居的加权聚合。因此，GAT 不仅对于噪音邻居较为鲁棒，注意力机制也赋予了模型一定的可解释性。
  - 非对称的注意力权重
  - Transformer 和 GAT 的主要区别是:
    - 在 GAT 中，作者对自注意力进行了简化。每个节点无论是作为中心节点/上下文/聚合输出，都只用一种表示h。也就是说，在 GAT 中，Q=K=V。【原来Transformer不一样？】
  - [源码](https://github.com/PetarV-/GAT)解读
    - 节点特征的话，先把特征维度压到1，压两遍，然后利用广播机制 [num_graph, num_node, 1] + [num_graph, 1, num_node]，得到[num_graph, num_node, num_node]
    - 边关系是用 node X node 维度的邻接矩阵描述的，为了让只学习有边连接的邻接节点的特征，邻接矩阵的值不是简单的0，1，根据归一化(softmax)的特点，不存在边关系的话用一个很小的值(-1e9)替代。
- 5、[关于图注意力网络（Graph Attention Network，GAT）知识汇总1.0](https://cloud.tencent.com/developer/article/2337199)
  - zhon
- 6、[图深度学习入门教程（六）——注意力机制与图注意力](https://cloud.tencent.com/developer/article/1614072)

# 2023.12.9 周六
## 1、日志
> 昨晚跟源妹妹一块吃了小民，所以没去武丰，所以今早有机会把程序给续上，试试我的方案有没有意义。  
> 然后昨晚看了下钢铁雄心的编制，我又觉得我行了。
>
> 突破就是进攻时的防御
>
> 入门了一下怪猎

# 周任务
- [ ] 划分论文第二部分整体框架
  - 首先把模型流程，也就是把代码流程先复述一遍。
  - 缺的模块，写在背景知识里面。比如AttentionLayer。
- [ ] 按顺序将轨迹预测的整个过程描述出来
  - [ ] 0、图注意力网络
  - [x] 1、地图编码
  - [x] 2、交通参与者编码
  - [ ] 3、粗预测
  - [ ] 4、再编码
  - [ ] 5、精细预测
  - [ ] 6、损失函数
- [ ] 小论文
  - [ ] 介绍
  - [ ] 相关工作
  - [ ] 方法
  - [ ] 实验
  - [ ] 结论与摘要

# 2023.12.11 周一
## 今日任务
- [x] 将第二部分待写内容定下
  - 还是很难定下来，但打算把整个模型流程全部写下来。
- psq的毕业论文第二部分写了两章
  - 2 基于高精地图的驾驶环境编码
    - 2.1 数据预处理
      - 数据集概述
      - 坐标转换
    - 2.2 节点特征编码
      - 交通参与者轨迹编码
      - 高精地图车道编码
      - 相对位置编码
    - 2.3 图神经网络构建【完全就是HiVT的编码部分】
      - 信息传递机制
      - 局部子图
      - 全局聚合图
  - 3 基于注意力机制的目标车辆轨迹预测
    - 3.1 目标车辆候选点生成及轨迹补全【TNT的解码】
      - 目标车辆候选点生成
      - 车道及目标车辆候选点打分
      - 轨迹补全
    - 3.2 轨迹预测模型的损失函数构建
      - 车道得分损失
      - 目标车辆候选点得分损失
      - 轨迹补全损失
    - 3.3 轨迹预测模型的多模态优化
      - 非极大值抑制
      - 爬山算法
- [x] 撰写地图编码部分
  - 把地图编码部分全部看了一遍，写了个大概出来。
  - 写的有缺陷，但着实太混乱了一点，应该理顺一点找到核心。

# 2023.12.12 周二
## 实验
- [x] q7_mec：QCNet初始代码，跑了40多个epoch就断了。
- [x] q8_mec：QCNet消融实验，无refine部分。早上9：45开始跑，大概57分钟train一个epoch。结果：val-minFDE：0.9589，
- [ ] 模范代码：Q7
  - [x] 预处理：将is_turn_direction, is_traffic_control加入。
  - [x] 预处理：self._object_types = ['AV', 'AGENT', 'OTHERS']
  - [x] agent编码：categorical_embs，编码self._object_types
  - [x] 预处理：agent速度：data['agent']['velocity'], 但速度也是基于位置算出来的，我还是觉得没什么意义。
  - [ ] 预处理：以AV为中心，Map半径仅有100
  - [x] agent编码: transpose修改
    - [x] 改了batch_s和batch_pl，改了一版出来，在Q3和Q3_mec里面，主要在MEC里测试。
    - [x] 改了edge_index_pl2a，但结果与原始的不一样
    - [x] 知道了为什么要transpose，torch_cluster.radius的batch_x和batch_y必须是排过序的

## 论文
- [x] 大论文：交通参与者编码
- [ ] 大论文：AttentionLayer的说明

  
## 进度
- 上午看油管视频，就把Agent代码看了一遍，没有写。
- 下午两点到工位
- 分析一下为什么需要transpose：
  - ![batch_s](/time/2023/12/img/屏幕截图%202023-12-12%20152316.png)
  - List[20 * Tensor(A)] -> Tensor(20*A)
  - List[A * Tensor(20)] -> Tensor(A*20)
  - 你妈两行代码写三个点，只改了batch_s和batch_pl
  - 但radius这个函数有点奇怪，我把batch_size调成1，相当于分类只分了20类，对应二十帧，但就这，结果还是不一样。
  - 破案啦，torch_cluster.radius的batch_x和batch_y必须是排过序的，所以啊，时间维度必须得在最前。
  - 得，一下午就看个这。

# 2023.12.14 周四
## 代码
- [x] 实验Q7-1，也就是我自己的模型改的第一版，
  - [x] 实验结果1: 1.167726, 1.86217。原始结果，1.156530, 1.8509。
  - [ ] 实验结果2：
- [x] 实验Q7-2，也就是把预处理修改了一波，模型整体还是QCNet
  - [x] 加入了type_a_emb，包括预处理的和模型里的。
  - [x] map_encode的self.int_pl_emb我发现源代码是3，但它的输出类型是bool，改成2了
  - [x] 加入了self.turn_pl_emb和self.cont_pl_emb，并加入了x_pl_categorical_embs。

## 论文
- [x] 大论文：交通参与者编码
- [ ] 大论文：AttentionLayer的说明
  - [x] 主题结构图
  - [ ] 书写形式
- [ ] 小论文：方法
  - [ ] 看QCNet是怎么写的。

## 进度
- 上午把交通参与者编码部分写了，还写了一部分图注意力网络。
- 下午现实看了四五十分钟的百度百科，然后把图注意力机制的代码又翻了翻，画了两个图，当然第二个应该用公式表示。图注意力网络还是没写完。


## 开会
要么一个研究点，要么两个研究点，一个应用系统。  
1、查重要求：单章不过5%，全文10%。  
2、不能有相关技术介绍。所以可能只有四章，不过要达到三万个字。  
3、每一章算法都要有结果，不能单独一章  
4、核心问题凝练，设计阶段有什么问题，提出一种方法。用什么方法解决，用什么方法实现
5、参考文献要近五年的。国内论文也要加，至少十篇。  
6、一月底定稿，三月十几号预答辩，四月初送审  
7、路测，应用来，清华数据集，轨迹预测碰撞验证，2045测试场，碰撞算法，应用场景，Unity  

# 2023.12.15 周五
## 总结
- 上午
  - 主要在改代码，创建了一个train.md，专门用来记录各个版本代码是什么意思。用md写表格挺好的，本来准备用csv，结果发现用Excel和VScode插件打开编码格式不同，果断放弃。现在在VScode下用md记笔记的唯一缺憾就是没有目录了。
  - 把预处理的bug解决了一下，现在用v2预处理的Q7_2可以跑了。
  - 然后发现Q7-1的代码只是换了顺序，再编码部分没有改。创建Q7-3，改了再编码部分，后面的精解码还没改好。
- 下午
  - 计划：改好Q7-3。然后写完大论文图部分。然后再看看QCNet论文。
  - 一下午就只改了个Q7-3的代码，而且核心问题还没解决，碰见麻烦了。
## 代码
- [ ] 创建Q7_2_mec：贴了一份Q7-2代码到MEC中
  - [x] debug: 预处理中的agent_type的维度创建错了。
  - [x] 开始处理预处理版本：main_qcnet_1。
  - [ ] 实验结果：
- [ ] 代码Q7-3，基于Q7-1，把refine从预测完整，修改为预测微调值。
  - 检查了一遍Q7-1，发现我只是把代码顺序变了一下，核心的再编码我没有动，还是GRU将20帧128叠成128。怪不得效果几乎差不多。
  - [x] 修改代码：再编码部分
  - [x] 修改代码：精解码部分
    - 碰上问题了，我的 m 编码后为 Tensor(3, A*6, 128), 然后取三次 Tensor(A*6, 128), 对应三次解码，但我只能计算，不能就着把 m 给改了，不然就会说我原地修改。
    - 相应的报错：one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [630, 128]], which is output 0 of AsStridedBackward0, is at version 39; expected version 38 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
    - 还是改了一版代码，但没有把m很好的用起来。
  - [ ] 跑实验：

# 2023.12.18 周一
## 总结
- 首先是实验
  - Q7_1的第二次实验差不多了，结果比第一次结果好一点。但没啥用。
  - 其次是Q7_2_mec的实验，这个我以为在跑，其实根本没有，只是train数据集看起来预处理好了，但实际上不能加载进来。
- 然后是周一总结
  - 我发现我这段时间大部分都在写代码相关的东西，而不是真的在写论文。整体代码确实必须得实验，但讲真v2的预处理能出来咱就用，不行就算了。
  - 上周写了一周，但没写多少，还是压力不够。那就摊派吧。
- 走神
  - [邓小平留下十大政治遗产](https://news.china.com/domesticgd/10000159/20170219/30265228.html)

## 今日任务
- [x] 图注意力介绍完成。
  - [Gentle introduction to graph neural and graph convolutional networks](https://www.avenga.com/magazine/graph-neural-networks-and-graph-convolutional-networks/)
  - [PyG中Message Passing机制详解](https://blog.csdn.net/weixin_43872709/article/details/123679423)
  - [Creating Message Passing Networks](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html#creating-message-passing-networks)
  - 1、神经网络与注意力机制的介绍；2、图数据结构的介绍；3、图神经网络的思想；4、图神经网络的流程（原理图）；5、图神经网络的流程（实现）
  - 完成情况：大体框架完成。
- [x] 总结QCNet论文提出的创新。
  - 过去的工作：
    - factorized attention-based Transformers, 每个时空场景。
    - 锚，长时预测
  - 总结
    - 首先，我们注意到，有可能实现更快的在线推理，同时也受益于因子化注意力的力量，但现有方法使用的以代理为中心的编码方案[25，27，46，56]是一个障碍。每次新的数据帧到达时，观察窗口向前滑动一步，并与其前一个窗口基本重叠，这为模型重用先前计算的编码提供了机会。然而，以代理为中心的方法需要根据最新的代理状态的位置对输入进行规范化，因此每当观察窗口向前滑动时，都需要对场景元素进行重新编码。为了解决这个问题，我们引入了一种**以查询为中心**的场景编码范式（见图1）。我们设计理念的关键在于在局部时空参考系中处理所有场景元素，并学习独立于全局坐标的表示。这种策略使我们能够缓存和重用以前计算的编码，将计算扩展到所有观察窗口，从而减少推理延迟。不变的场景特征也可以在场景中的所有目标代理之间共享，以实现多代理解码的并行性。
    - 其次，为了更好地利用场景编码进行多模式和长期预测，我们使用**无锚查询**来递归地检索场景上下文，并让它们在**每次递归时解码一小段未来的路点**。这种循环机制通过允许查询在预测不同地平线上的路点时关注不同的场景上下文，减轻了查询的建模负担。递归解码器预测的高质量轨迹在随后的细化模块中充当动态锚点，在该模块中，我们使用基于锚点的查询来基于场景上下文细化轨迹建议。因此，我们基于查询的解码管道将无锚方法的灵活性融入到基于锚的解决方案中，两全其美，促进了多模式和长期预测。
  - 方法
    - 1、输入和输出公式
    - 2、以查询为中心的场景编码
      - 本地时空坐标系
      - 场景元素嵌入
      - 相对时空位置嵌入
      - Self-Attention for Map Encoding：自注意力
      - Factorized Attention for Agent Encoding：因子化注意力。
        - 这好像在[wayformer](https://zhuanlan.zhihu.com/p/582632248)里面提到。
    - 3、基于query的轨迹解码
      - Mode2Scene and Mode2Mode Attention：提议和细化模块都使用类似DETR的体系结构。类似于DETR[4]中对象查询的概念，每个查询负责解码K个轨迹模式中的一个。在Mode2Scene Attention中，我们使用cross Attention层来更新具有多个上下文的模式查询，包括目标代理的历史编码、映射编码和相邻代理的编码。在Mode2Scene Attention之后，K模式通过Mode2Mode自注意力相互查询“talk”，以提高多种模式的多样性。【就很扯，明显是scene2mode啊。】
      - Reference Frames of Mode Queries（模式查询的参考框架）：共享相同的场景编码。
      - Anchor-Free Trajectory Proposal.
      - Anchor-Based Trajectory Refinement
    - 4、训练目标：损失函数
- [ ] 确定小论文大纲
  - 还真得按编码解码写。很显然，QCNet的创新点一是时间复杂度分析，二是结构。
  - 所以我得想办法造词。



