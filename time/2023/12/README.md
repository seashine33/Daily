# 2023.12.1 周五
- [x] 把相关超参数全部调成初始值，再做实验，看是不是过拟合，不管是什么原因的过拟合。
> 我拿初始的epoch 1进行test，结果为11多，看来还是模型代码的问题。


- [x] 除了调参以外，还可以把计算loss的过程改为把预测值旋转平移到世界坐标系，与真值求欧氏距离。  
> 不肯是旋转平移的问题了，因为我拿test代码跑了val的，没有问题，直接看散点图都没问题。


- [ ] Risk Assessment 帖子推荐的第一篇论文是讲AV的风险评估(RA)的，重点看看。
> 风险评估方法

- [x] 昨晚突然想出来的法子，test集没有真值，我拿val集走一遍test代码，拿结果对比一下。
> 为了方便，首先把test_obs和val文件名相互替换。  
> test代码好像不管其他的数据，直接拉了val前1000数据过来当test的some，把结果存到test的some_result里面，最后发现，预测效果很好，效果好不是假的。  
> 那就真见鬼了，除非我拿val集训练了，不然这也太怪了。又看了一下，val代码连loss都没有输出，怎么可能训练了。  
> 那，到底是为什么呢？  
> 我发现一个特征，val数据跑出来的数据，Excel可以一下子识别出来散点图，但test就识别不出来，反正就是val什么都是好的，test啥啥不行，**是不是test的编码有问题啊**，没有兼容。  
> 或者说，完整轨迹就是OK的，不完整轨迹就是有问题。

- [x] test数据的编码过程有没有问题？
> test又分了几个文件夹  
> some_val, some_test 分别存了val和test前一千个场景  
> some_qcnet_val, some_qcnet_test分别是其编码信息，  
> some_result_val, some_result_test分别存了预测结果。  
>
> 然后就是看代码了，后面再看吧。
>
> 发现问题了，见 12.4 part 1。

周五下午两点半，已经不想学了。验证上面那一点竟然弄了四个小时。  
我竟然连菜都忘了收？  
一来就验证数据去了。

# 2023.12.4 周一
## 1、QCNet代码test部分找到问题所在了
> 首先是看test数据集，因为不存在未来数据，看是否对训练过程有影响  
> 道路编码，以AV为中心，考虑半径怎么才100？  
> 果然，解码的时候用到了'predict_mask'，我看这一步的备注是“只有存在未来步才预测”，好家伙。  
> 把预处理的部分改了一下，再跑一遍试试。【重大进步】  
> FDE 1.20，我总算是，四个月，总算是找到问题所在了。  
> 然后这个数据我是拿QCNet的原始超参数进行的test，与训练过程的test不同，后面我要进行多次实验。

- [ ] 超参数调整，test过程的超参数设置对结果的影响如何。
> QCNet原始超参数, q3, version_5, epoch_54, FDE 1.20, bFDE：1.899  
> 新参数, q3, version_5, epoch_54, 这个是0.000001的区别
> 
> QCNet原始超参数，version_1，epoch_43，FDE 1.22，bFDE：1.915  
> 新参数，version_1，epoch_43, ？竟然结果一样, 哦，有0.0000001的区别
> 在MEC上处理。
>
> 所以结论是，这些半径什么的超参数不重要。

## 2、写场景介绍，画场景图。
> 打算看看论文，看不下去。  
> 打打游戏缓缓。   

> 结果拉着开会，要写场景的文档。  
> 写差不多了，晚上又得开会  
> 讨论场景为交叉路口，场景参与方有若干行人与车辆；车辆在机动车道上行驶，行人在人行横道上行走。路测端传感器实时识别追踪并记录下场景中各个参与者的位置，作为轨迹预测模块使用的历史轨迹。轨迹预测模块基于场景中所有参与者的历史轨迹，结合场景地图数据，进行预测时长为5秒的多模态预测。碰撞风险评估模块基于多模态未来轨迹，评判场景中各参与者的碰撞风险。对碰撞风险过高的场景参与者进行预警，如行人通过APP得到预警，使其注意周边车辆。  
> 图的话，可以用一个在线画图网站：  
> https://products.aspose.app/diagram/zh-cn/editor  

> 代码终于可以跑啦，轻松多了。  
> 发现QCNet初始数据可以以batch_size 16跑，可以，理论上四天多就可以跑完。  

# 2023.12.5 周二
## 1、QCNet 实验
> 跑实验，显存占用率太高了只剩二十几兆。  
> 玩了会MEC，准备把代码备份一下。  
> 把所有的结果都放到q1里面去了，减小q3的大小。  
> 把数据备份到U盘了，然后拷了一份到MEC上，给MEC装上QCNet的环境。  
> 现在正在跑的代码大概1.5h一个epoch，4天跑完，这4天把已有的模型测一下。  
> 每次配环境的时候，需要把map_file移到环境文件夹下，今天发现原来是初始化am时没有指定文件夹。  

> 新建了q7，用来实现经过几个月沉淀的方案。  
> 首先把代码整理了一下，主要删除了一些用于av1与av2兼容的代码，主要是head。  
> 

## 2、Risk Assessment方法
> [碰撞评估综述](/note/Risk%20Assessment/node/Risk_Assessment_Methodologies_for_Autonomous_Driving_A_Survey.md)


# 2023.12.6 周三
> 睡到中午起  
> 吃饭接着睡午觉  
> 三点起来去东湖玩，七个人  
> 吃完饭打牌  
> 一点到寝室睡觉  

# 2023.12.7 周四
## 1、QCNet实验
> 感觉用初始参数效果会更好啊。
> 38个epoch就到了自己设的参数了。

## 2、Risk Assessment方法
> [碰撞评估综述](/note/Risk%20Assessment/node/Risk_Assessment_Methodologies_for_Autonomous_Driving_A_Survey.md)

## 3、毕业论文
> 了解了一下，这TM才是最重要的部分，甚至看什么综述都属于是非常浪费时间   
> 开始急躁了，在实验室根本不能得到安宁了  
> 后面得调作息 + 去图书馆了  

## 4、修改QCNet代码
> 论文看不进去，想该改改代码。
> 先不上手改吧，先把结构图画出来。


- [ ] 实验：QCNet去掉第二次解码，结果是多少？
> 结果
> 
- [ ] 改代码
> 1、QCNet的m是由(6,128)repeat出来的，而我的是(A,128)repeat出来的，检查保证统一，再编码的部分，m的维度也要实验一下，这大概就能弄懂为什么会有transpose了吧  
> 2、QCNet的refine是初始值的修正值，也就是refine+rough才是第二次预测的结果。相应的scale也有区别，这要做实验确认哪个效果好。

闹钟定了，计划下了，感叹完了  
然后发出脱离互联网能不能活的疑惑  

# 2023.12.8 周五
## 1、日结
> 早上确实是八点半起来的，但昨晚三点还没睡着  
> 起来还算是清醒，但肯定要睡午觉  
> 到实验室九点，刚好开始上班

## 2、QCNet
> 跑到epoch=49了，相比昨天下午又有轻微的增长

## 3、毕业论文
- 1、粗略读彭赛骞论文
  - 第二章主要介绍了Argoverse数据集，还有地图数据格式，图神经网络。
  - 第三章讲了基于目标的轨迹预测流程
  - 第四章碰撞风险评估，就不太熟悉了。
- 2、重读《QCNet》
  - 终于读懂了以代理（Agent）为中心，以查询（query）为中心是什么意思。
  - 之前使用地图数据：将所有路点基于车辆进行旋转平移，再编码。
  - 现在使用地图数据：将所有polygon（polygon初始waypoint位置）与waypoint（waypoint间的距离）的关系建立好，然后都embedded到128维，然后将waypoint间的距离编码到polygon里面，再polygon相互编码。
  - 以解码策略难以捕捉多模态为理由，进行无锚、有锚预测的区分。
  - 图一说明了其对每步每帧都进行了编码。
  - 观察窗口，我大概明白他的意思，也就是以代理为中心的情况下，历史时间变化了，对应的所有代理也要重新编码。
- 3、[注意力机制综述](https://zhuanlan.zhihu.com/p/631398525)
  - 自注意力机制
    - 首先对输入x进行embedding，得到a。
      - 假设映射到128维
    - a会乘三个矩阵w(qkv)，得到qkv，这三个矩阵在整个过程中共享
    - q（query）的含义一般解释是用来与其他单词进行匹配，或者说计算当前单词与其他单词之间的关系。
    - k（key）用来与q进行匹配，或者说单词的关键信息。
    - 若要计算a1与a1234之间的关系，需要q1，和k1234进行匹配计算，得到α1234
      - α1为两128维向量点乘后除根号128，为一个float型
    - 对α1234进行softmax操作，得到~α1234。
      - ~α1234，4个大于0的float型和为1
    - v（value）的含义主要表示当前单词的重要信息。
    - v1234与~a1234按序号相乘后求和，得到b1。
      - b1根据相似性包含了a1234的信息，为128维向量。
    - ![tup](/time/2023/12/img/屏幕截图%202023-12-08%20114411.png)
  - 多头自注意力机制
    - 多头注意力机制是在自注意力机制的基础上发展起来的，是自注意力机制的变体,旨在增强模型的表达能力和泛化能力。它通过使用多个独立的注意力头，分别计算注意力权重，并将它们的结果进行拼接或加权求和，从而获得更丰富的表示。
    - 看代码会简单一些
  - 通道注意力机制
    - 图像数据有多通道，例如RGB三通道【这里的理解很主观】，其是对每个通道求一个标量，用来学习每个通道的权重。
    - [ ] 可以类比，比如对每个Agent求一个权重。
  - 空间注意力机制
    - 空间注意力机制和通道注意力机制具有异曲同工之妙，通道注意力机制旨在捕捉通道的重要性的程度，空间注意力机制旨在通过引入注意力模块，使模型能够自适应地学习不同区域的注意力权重。这样，模型可以更加关注重要的图像区域，而忽略不重要的区域。
- 4、[深入理解图注意力机制(Graph Attention Network)](https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/105548217)
  - 作为一种代表性的图卷积网络，Graph Attention Network (GAT) 引入了注意力机制来实现更好的邻居聚合。通过学习邻居的权重，GAT 可以实现对邻居的加权聚合。因此，GAT 不仅对于噪音邻居较为鲁棒，注意力机制也赋予了模型一定的可解释性。
  - 非对称的注意力权重
  - Transformer 和 GAT 的主要区别是:
    - 在 GAT 中，作者对自注意力进行了简化。每个节点无论是作为中心节点/上下文/聚合输出，都只用一种表示h。也就是说，在 GAT 中，Q=K=V。【原来Transformer不一样？】
  - [源码](https://github.com/PetarV-/GAT)解读
    - 节点特征的话，先把特征维度压到1，压两遍，然后利用广播机制 [num_graph, num_node, 1] + [num_graph, 1, num_node]，得到[num_graph, num_node, num_node]
    - 边关系是用 node X node 维度的邻接矩阵描述的，为了让只学习有边连接的邻接节点的特征，邻接矩阵的值不是简单的0，1，根据归一化(softmax)的特点，不存在边关系的话用一个很小的值(-1e9)替代。
    - 