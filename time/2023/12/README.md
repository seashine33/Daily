# 2023.12.1 周五
- [x] 把相关超参数全部调成初始值，再做实验，看是不是过拟合，不管是什么原因的过拟合。
> 我拿初始的epoch 1进行test，结果为11多，看来还是模型代码的问题。


- [x] 除了调参以外，还可以把计算loss的过程改为把预测值旋转平移到世界坐标系，与真值求欧氏距离。  
> 不肯是旋转平移的问题了，因为我拿test代码跑了val的，没有问题，直接看散点图都没问题。


- [ ] Risk Assessment 帖子推荐的第一篇论文是讲AV的风险评估(RA)的，重点看看。
> 风险评估方法

- [x] 昨晚突然想出来的法子，test集没有真值，我拿val集走一遍test代码，拿结果对比一下。
> 为了方便，首先把test_obs和val文件名相互替换。  
> test代码好像不管其他的数据，直接拉了val前1000数据过来当test的some，把结果存到test的some_result里面，最后发现，预测效果很好，效果好不是假的。  
> 那就真见鬼了，除非我拿val集训练了，不然这也太怪了。又看了一下，val代码连loss都没有输出，怎么可能训练了。  
> 那，到底是为什么呢？  
> 我发现一个特征，val数据跑出来的数据，Excel可以一下子识别出来散点图，但test就识别不出来，反正就是val什么都是好的，test啥啥不行，**是不是test的编码有问题啊**，没有兼容。  
> 或者说，完整轨迹就是OK的，不完整轨迹就是有问题。

- [x] test数据的编码过程有没有问题？
> test又分了几个文件夹  
> some_val, some_test 分别存了val和test前一千个场景  
> some_qcnet_val, some_qcnet_test分别是其编码信息，  
> some_result_val, some_result_test分别存了预测结果。  
>
> 然后就是看代码了，后面再看吧。
>
> 发现问题了，见 12.4 part 1。

周五下午两点半，已经不想学了。验证上面那一点竟然弄了四个小时。  
我竟然连菜都忘了收？  
一来就验证数据去了。

############################# 第一周 ###################################

# 2023.12.4 周一
## 1、QCNet代码test部分找到问题所在了
> 首先是看test数据集，因为不存在未来数据，看是否对训练过程有影响  
> 道路编码，以AV为中心，考虑半径怎么才100？  
> 果然，解码的时候用到了'predict_mask'，我看这一步的备注是“只有存在未来步才预测”，好家伙。  
> 把预处理的部分改了一下，再跑一遍试试。【重大进步】  
> FDE 1.20，我总算是，四个月，总算是找到问题所在了。  
> 然后这个数据我是拿QCNet的原始超参数进行的test，与训练过程的test不同，后面我要进行多次实验。

- [ ] 超参数调整，test过程的超参数设置对结果的影响如何。
> QCNet原始超参数, q3, version_5, epoch_54, FDE 1.20, bFDE：1.899  
> 新参数, q3, version_5, epoch_54, 这个是0.000001的区别
> 
> QCNet原始超参数，version_1，epoch_43，FDE 1.22，bFDE：1.915  
> 新参数，version_1，epoch_43, ？竟然结果一样, 哦，有0.0000001的区别
> 在MEC上处理。
>
> 所以结论是，这些半径什么的超参数不重要。

## 2、写场景介绍，画场景图。
> 打算看看论文，看不下去。  
> 打打游戏缓缓。   

> 结果拉着开会，要写场景的文档。  
> 写差不多了，晚上又得开会  
> 讨论场景为交叉路口，场景参与方有若干行人与车辆；车辆在机动车道上行驶，行人在人行横道上行走。路测端传感器实时识别追踪并记录下场景中各个参与者的位置，作为轨迹预测模块使用的历史轨迹。轨迹预测模块基于场景中所有参与者的历史轨迹，结合场景地图数据，进行预测时长为5秒的多模态预测。碰撞风险评估模块基于多模态未来轨迹，评判场景中各参与者的碰撞风险。对碰撞风险过高的场景参与者进行预警，如行人通过APP得到预警，使其注意周边车辆。  
> 图的话，可以用一个在线画图网站：  
> https://products.aspose.app/diagram/zh-cn/editor  

> 代码终于可以跑啦，轻松多了。  
> 发现QCNet初始数据可以以batch_size 16跑，可以，理论上四天多就可以跑完。  

# 2023.12.5 周二
## 1、QCNet 实验
> 跑实验，显存占用率太高了只剩二十几兆。  
> 玩了会MEC，准备把代码备份一下。  
> 把所有的结果都放到q1里面去了，减小q3的大小。  
> 把数据备份到U盘了，然后拷了一份到MEC上，给MEC装上QCNet的环境。  
> 现在正在跑的代码大概1.5h一个epoch，4天跑完，这4天把已有的模型测一下。  
> 每次配环境的时候，需要把map_file移到环境文件夹下，今天发现原来是初始化am时没有指定文件夹。  

> 新建了q7，用来实现经过几个月沉淀的方案。  
> 首先把代码整理了一下，主要删除了一些用于av1与av2兼容的代码，主要是head。  
> 

## 2、Risk Assessment方法
> [碰撞评估综述](/note/Risk%20Assessment/node/Risk_Assessment_Methodologies_for_Autonomous_Driving_A_Survey.md)


# 2023.12.6 周三
> 睡到中午起  
> 吃饭接着睡午觉  
> 三点起来去东湖玩，七个人  
> 吃完饭打牌  
> 一点到寝室睡觉  

# 2023.12.7 周四
## 1、QCNet实验
> 感觉用初始参数效果会更好啊。
> 38个epoch就到了自己设的参数了。

## 2、Risk Assessment方法
> [碰撞评估综述](/note/Risk%20Assessment/node/Risk_Assessment_Methodologies_for_Autonomous_Driving_A_Survey.md)

## 3、毕业论文
> 了解了一下，这TM才是最重要的部分，甚至看什么综述都属于是非常浪费时间   
> 开始急躁了，在实验室根本不能得到安宁了  
> 后面得调作息 + 去图书馆了  

## 4、修改QCNet代码
> 论文看不进去，想该改改代码。
> 先不上手改吧，先把结构图画出来。


- [ ] 实验：QCNet去掉第二次解码，结果是多少？
> 结果
> 
- [ ] 改代码
> 1、QCNet的m是由(6,128)repeat出来的，而我的是(A,128)repeat出来的，检查保证统一，再编码的部分，m的维度也要实验一下，这大概就能弄懂为什么会有transpose了吧  
> 2、QCNet的refine是初始值的修正值，也就是refine+rough才是第二次预测的结果。相应的scale也有区别，这要做实验确认哪个效果好。

闹钟定了，计划下了，感叹完了  
然后发出脱离互联网能不能活的疑惑  

# 2023.12.8 周五
## 1、日结
> 早上确实是八点半起来的，但昨晚三点还没睡着  
> 起来还算是清醒，但肯定要睡午觉  
> 到实验室九点，刚好开始上班

## 2、QCNet
> 跑到epoch=49了，相比昨天下午又有轻微的增长

## 3、毕业论文
- 1、粗略读彭赛骞论文
  - 第二章主要介绍了Argoverse数据集，还有地图数据格式，图神经网络。
  - 第三章讲了基于目标的轨迹预测流程
  - 第四章碰撞风险评估，就不太熟悉了。
- 2、重读《QCNet》
  - 终于读懂了以代理（Agent）为中心，以查询（query）为中心是什么意思。
  - 之前使用地图数据：将所有路点基于车辆进行旋转平移，再编码。
  - 现在使用地图数据：将所有polygon（polygon初始waypoint位置）与waypoint（waypoint间的距离）的关系建立好，然后都embedded到128维，然后将waypoint间的距离编码到polygon里面，再polygon相互编码。
  - 以解码策略难以捕捉多模态为理由，进行无锚、有锚预测的区分。
  - 图一说明了其对每步每帧都进行了编码。
  - 观察窗口，我大概明白他的意思，也就是以代理为中心的情况下，历史时间变化了，对应的所有代理也要重新编码。
- 3、[注意力机制综述](https://zhuanlan.zhihu.com/p/631398525)
  - 自注意力机制
    - 首先对输入x进行embedding，得到a。
      - 假设映射到128维
    - a会乘三个矩阵w(qkv)，得到qkv，这三个矩阵在整个过程中共享
    - q（query）的含义一般解释是用来与其他单词进行匹配，或者说计算当前单词与其他单词之间的关系。
    - k（key）用来与q进行匹配，或者说单词的关键信息。
    - 若要计算a1与a1234之间的关系，需要q1，和k1234进行匹配计算，得到α1234
      - α1为两128维向量点乘后除根号128，为一个float型
    - 对α1234进行softmax操作，得到~α1234。
      - ~α1234，4个大于0的float型和为1
    - v（value）的含义主要表示当前单词的重要信息。
    - v1234与~a1234按序号相乘后求和，得到b1。
      - b1根据相似性包含了a1234的信息，为128维向量。
    - ![tup](/time/2023/12/img/屏幕截图%202023-12-08%20114411.png)
  - 多头自注意力机制
    - 多头注意力机制是在自注意力机制的基础上发展起来的，是自注意力机制的变体,旨在增强模型的表达能力和泛化能力。它通过使用多个独立的注意力头，分别计算注意力权重，并将它们的结果进行拼接或加权求和，从而获得更丰富的表示。
    - 看代码会简单一些
  - 通道注意力机制
    - 图像数据有多通道，例如RGB三通道【这里的理解很主观】，其是对每个通道求一个标量，用来学习每个通道的权重。
    - [ ] 可以类比，比如对每个Agent求一个权重。
  - 空间注意力机制
    - 空间注意力机制和通道注意力机制具有异曲同工之妙，通道注意力机制旨在捕捉通道的重要性的程度，空间注意力机制旨在通过引入注意力模块，使模型能够自适应地学习不同区域的注意力权重。这样，模型可以更加关注重要的图像区域，而忽略不重要的区域。
- 4、[深入理解图注意力机制(Graph Attention Network)](https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/105548217)
  - 作为一种代表性的图卷积网络，Graph Attention Network (GAT) 引入了注意力机制来实现更好的邻居聚合。通过学习邻居的权重，GAT 可以实现对邻居的加权聚合。因此，GAT 不仅对于噪音邻居较为鲁棒，注意力机制也赋予了模型一定的可解释性。
  - 非对称的注意力权重
  - Transformer 和 GAT 的主要区别是:
    - 在 GAT 中，作者对自注意力进行了简化。每个节点无论是作为中心节点/上下文/聚合输出，都只用一种表示h。也就是说，在 GAT 中，Q=K=V。【原来Transformer不一样？】
  - [源码](https://github.com/PetarV-/GAT)解读
    - 节点特征的话，先把特征维度压到1，压两遍，然后利用广播机制 [num_graph, num_node, 1] + [num_graph, 1, num_node]，得到[num_graph, num_node, num_node]
    - 边关系是用 node X node 维度的邻接矩阵描述的，为了让只学习有边连接的邻接节点的特征，邻接矩阵的值不是简单的0，1，根据归一化(softmax)的特点，不存在边关系的话用一个很小的值(-1e9)替代。
- 5、[关于图注意力网络（Graph Attention Network，GAT）知识汇总1.0](https://cloud.tencent.com/developer/article/2337199)
  - zhon
- 6、[图深度学习入门教程（六）——注意力机制与图注意力](https://cloud.tencent.com/developer/article/1614072)

# 2023.12.9 周六
## 1、日志
> 昨晚跟源妹妹一块吃了小民，所以没去武丰，所以今早有机会把程序给续上，试试我的方案有没有意义。  
> 然后昨晚看了下钢铁雄心的编制，我又觉得我行了。
>
> 突破就是进攻时的防御
>
> 入门了一下怪猎


############################# 第二周 ###################################
# 周任务
- [ ] 划分论文第二部分整体框架
  - 首先把模型流程，也就是把代码流程先复述一遍。
  - 缺的模块，写在背景知识里面。比如AttentionLayer。
- [ ] 按顺序将轨迹预测的整个过程描述出来
  - [ ] 0、图注意力网络
  - [x] 1、地图编码
  - [x] 2、交通参与者编码
  - [ ] 3、粗预测
  - [ ] 4、再编码
  - [ ] 5、精细预测
  - [ ] 6、损失函数
- [ ] 小论文
  - [ ] 介绍
  - [ ] 相关工作
  - [ ] 方法
  - [ ] 实验
  - [ ] 结论与摘要

# 2023.12.11 周一
## 今日任务
- [x] 将第二部分待写内容定下
  - 还是很难定下来，但打算把整个模型流程全部写下来。
- psq的毕业论文第二部分写了两章
  - 2 基于高精地图的驾驶环境编码
    - 2.1 数据预处理
      - 数据集概述
      - 坐标转换
    - 2.2 节点特征编码
      - 交通参与者轨迹编码
      - 高精地图车道编码
      - 相对位置编码
    - 2.3 图神经网络构建【完全就是HiVT的编码部分】
      - 信息传递机制
      - 局部子图
      - 全局聚合图
  - 3 基于注意力机制的目标车辆轨迹预测
    - 3.1 目标车辆候选点生成及轨迹补全【TNT的解码】
      - 目标车辆候选点生成
      - 车道及目标车辆候选点打分
      - 轨迹补全
    - 3.2 轨迹预测模型的损失函数构建
      - 车道得分损失
      - 目标车辆候选点得分损失
      - 轨迹补全损失
    - 3.3 轨迹预测模型的多模态优化
      - 非极大值抑制
      - 爬山算法
- [x] 撰写地图编码部分
  - 把地图编码部分全部看了一遍，写了个大概出来。
  - 写的有缺陷，但着实太混乱了一点，应该理顺一点找到核心。

# 2023.12.12 周二
## 实验
- [x] q7_mec：QCNet初始代码，跑了40多个epoch就断了。
- [x] q8_mec：QCNet消融实验，无refine部分。早上9：45开始跑，大概57分钟train一个epoch。结果：val-minFDE：0.9589，
- [ ] 模范代码：Q7
  - [x] 预处理：将is_turn_direction, is_traffic_control加入。
  - [x] 预处理：self._object_types = ['AV', 'AGENT', 'OTHERS']
  - [x] agent编码：categorical_embs，编码self._object_types
  - [x] 预处理：agent速度：data['agent']['velocity'], 但速度也是基于位置算出来的，我还是觉得没什么意义。
  - [ ] 预处理：以AV为中心，Map半径仅有100
  - [x] agent编码: transpose修改
    - [x] 改了batch_s和batch_pl，改了一版出来，在Q3和Q3_mec里面，主要在MEC里测试。
    - [x] 改了edge_index_pl2a，但结果与原始的不一样
    - [x] 知道了为什么要transpose，torch_cluster.radius的batch_x和batch_y必须是排过序的

## 论文
- [x] 大论文：交通参与者编码
- [ ] 大论文：AttentionLayer的说明

  
## 进度
- 上午看油管视频，就把Agent代码看了一遍，没有写。
- 下午两点到工位
- 分析一下为什么需要transpose：
  - ![batch_s](/time/2023/12/img/屏幕截图%202023-12-12%20152316.png)
  - List[20 * Tensor(A)] -> Tensor(20*A)
  - List[A * Tensor(20)] -> Tensor(A*20)
  - 你妈两行代码写三个点，只改了batch_s和batch_pl
  - 但radius这个函数有点奇怪，我把batch_size调成1，相当于分类只分了20类，对应二十帧，但就这，结果还是不一样。
  - 破案啦，torch_cluster.radius的batch_x和batch_y必须是排过序的，所以啊，时间维度必须得在最前。
  - 得，一下午就看个这。

# 2023.12.14 周四
## 代码
- [x] 实验Q7-1，也就是我自己的模型改的第一版，
  - [x] 实验结果1: 1.167726, 1.86217。原始结果，1.156530, 1.8509。
  - [ ] 实验结果2：
- [x] 实验Q7-2，也就是把预处理修改了一波，模型整体还是QCNet
  - [x] 加入了type_a_emb，包括预处理的和模型里的。
  - [x] map_encode的self.int_pl_emb我发现源代码是3，但它的输出类型是bool，改成2了
  - [x] 加入了self.turn_pl_emb和self.cont_pl_emb，并加入了x_pl_categorical_embs。

## 论文
- [x] 大论文：交通参与者编码
- [ ] 大论文：AttentionLayer的说明
  - [x] 主题结构图
  - [ ] 书写形式
- [ ] 小论文：方法
  - [ ] 看QCNet是怎么写的。

## 进度
- 上午把交通参与者编码部分写了，还写了一部分图注意力网络。
- 下午现实看了四五十分钟的百度百科，然后把图注意力机制的代码又翻了翻，画了两个图，当然第二个应该用公式表示。图注意力网络还是没写完。


## 开会
要么一个研究点，要么两个研究点，一个应用系统。  
1、查重要求：单章不过5%，全文10%。  
2、不能有相关技术介绍。所以可能只有四章，不过要达到三万个字。  
3、每一章算法都要有结果，不能单独一章  
4、核心问题凝练，设计阶段有什么问题，提出一种方法。用什么方法解决，用什么方法实现
5、参考文献要近五年的。国内论文也要加，至少十篇。  
6、一月底定稿，三月十几号预答辩，四月初送审  
7、路测，应用来，清华数据集，轨迹预测碰撞验证，2045测试场，碰撞算法，应用场景，Unity  

# 2023.12.15 周五
## 总结
- 上午
  - 主要在改代码，创建了一个train.md，专门用来记录各个版本代码是什么意思。用md写表格挺好的，本来准备用csv，结果发现用Excel和VScode插件打开编码格式不同，果断放弃。现在在VScode下用md记笔记的唯一缺憾就是没有目录了。
  - 把预处理的bug解决了一下，现在用v2预处理的Q7_2可以跑了。
  - 然后发现Q7-1的代码只是换了顺序，再编码部分没有改。创建Q7-3，改了再编码部分，后面的精解码还没改好。
- 下午
  - 计划：改好Q7-3。然后写完大论文图部分。然后再看看QCNet论文。
  - 一下午就只改了个Q7-3的代码，而且核心问题还没解决，碰见麻烦了。
## 代码
- [ ] 创建Q7_2_mec：贴了一份Q7-2代码到MEC中
  - [x] debug: 预处理中的agent_type的维度创建错了。
  - [x] 开始处理预处理版本：main_qcnet_1。
  - [ ] 实验结果：
- [ ] 代码Q7-3，基于Q7-1，把refine从预测完整，修改为预测微调值。
  - 检查了一遍Q7-1，发现我只是把代码顺序变了一下，核心的再编码我没有动，还是GRU将20帧128叠成128。怪不得效果几乎差不多。
  - [x] 修改代码：再编码部分
  - [x] 修改代码：精解码部分
    - 碰上问题了，我的 m 编码后为 Tensor(3, A*6, 128), 然后取三次 Tensor(A*6, 128), 对应三次解码，但我只能计算，不能就着把 m 给改了，不然就会说我原地修改。
    - 相应的报错：one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [630, 128]], which is output 0 of AsStridedBackward0, is at version 39; expected version 38 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
    - 还是改了一版代码，但没有把m很好的用起来。
  - [ ] 跑实验：

############################# 第三周 ###################################
# 2023.12.18 周一
## 总结
- 首先是实验
  - Q7_1的第二次实验差不多了，结果比第一次结果好一点。但没啥用。
  - 其次是Q7_2_mec的实验，这个我以为在跑，其实根本没有，只是train数据集看起来预处理好了，但实际上不能加载进来。
- 然后是周一总结
  - 我发现我这段时间大部分都在写代码相关的东西，而不是真的在写论文。整体代码确实必须得实验，但讲真v2的预处理能出来咱就用，不行就算了。
  - 上周写了一周，但没写多少，还是压力不够。那就摊派吧。
- 走神
  - [邓小平留下十大政治遗产](https://news.china.com/domesticgd/10000159/20170219/30265228.html)

## 今日任务
- [x] 图注意力介绍完成。
  - [Gentle introduction to graph neural and graph convolutional networks](https://www.avenga.com/magazine/graph-neural-networks-and-graph-convolutional-networks/)
  - [PyG中Message Passing机制详解](https://blog.csdn.net/weixin_43872709/article/details/123679423)
  - [Creating Message Passing Networks](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html#creating-message-passing-networks)
  - 1、神经网络与注意力机制的介绍；2、图数据结构的介绍；3、图神经网络的思想；4、图神经网络的流程（原理图）；5、图神经网络的流程（实现）
  - 完成情况：大体框架完成。
- [x] 总结QCNet论文提出的创新。
  - 过去的工作：
    - factorized attention-based Transformers, 每个时空场景。
    - 锚，长时预测
  - 总结
    - 首先，我们注意到，有可能实现更快的在线推理，同时也受益于因子化注意力的力量，但现有方法使用的以代理为中心的编码方案[25，27，46，56]是一个障碍。每次新的数据帧到达时，观察窗口向前滑动一步，并与其前一个窗口基本重叠，这为模型重用先前计算的编码提供了机会。然而，以代理为中心的方法需要根据最新的代理状态的位置对输入进行规范化，因此每当观察窗口向前滑动时，都需要对场景元素进行重新编码。为了解决这个问题，我们引入了一种**以查询为中心**的场景编码范式（见图1）。我们设计理念的关键在于在局部时空参考系中处理所有场景元素，并学习独立于全局坐标的表示。这种策略使我们能够缓存和重用以前计算的编码，将计算扩展到所有观察窗口，从而减少推理延迟。不变的场景特征也可以在场景中的所有目标代理之间共享，以实现多代理解码的并行性。
    - 其次，为了更好地利用场景编码进行多模式和长期预测，我们使用**无锚查询**来递归地检索场景上下文，并让它们在**每次递归时解码一小段未来的路点**。这种循环机制通过允许查询在预测不同地平线上的路点时关注不同的场景上下文，减轻了查询的建模负担。递归解码器预测的高质量轨迹在随后的细化模块中充当动态锚点，在该模块中，我们使用基于锚点的查询来基于场景上下文细化轨迹建议。因此，我们基于查询的解码管道将无锚方法的灵活性融入到基于锚的解决方案中，两全其美，促进了多模式和长期预测。
  - 方法
    - 1、输入和输出公式
    - 2、以query为中心的场景编码
      - 本地时空坐标系
      - 场景元素嵌入
      - 相对时空位置嵌入
      - Self-Attention for Map Encoding：自注意力
      - Factorized Attention for Agent Encoding：因子化注意力。
        - 这好像在[wayformer](https://zhuanlan.zhihu.com/p/582632248)里面提到。
    - 3、基于query的轨迹解码
      - Mode2Scene and Mode2Mode Attention：提议和细化模块都使用类似DETR的体系结构。类似于DETR[4]中对象查询的概念，每个查询负责解码K个轨迹模式中的一个。在Mode2Scene Attention中，我们使用cross Attention层来更新具有多个上下文的模式查询，包括目标代理的历史编码、映射编码和相邻代理的编码。在Mode2Scene Attention之后，K模式通过Mode2Mode自注意力相互查询“talk”，以提高多种模式的多样性。【就很扯，明显是scene2mode啊。】
      - Reference Frames of Mode Queries（模式查询的参考框架）：共享相同的场景编码。
      - Anchor-Free Trajectory Proposal.
      - Anchor-Based Trajectory Refinement
    - 4、训练目标：损失函数
- [ ] 确定小论文大纲
  - 还真得按编码解码写。很显然，QCNet的创新点一是时间复杂度分析，二是结构。
  - 所以我得想办法造词。

# 2023.12.19 周二
## 总结
- 上午想了想小论文怎么写，有哪些创新点什么的，编码过程大概就是围绕最小编码单元展开，解码阶段我还没想好，先把解码阶段的大论文部分写出来吧。
- 然后还画了个图，也就是类似暑假时候用笔画的图。vscode真的啥都能干。
- [ ] 超参数num_t2m_steps设置的30，理论上应该小于20。设成30刚好跟10效果一样。
- [ ] angle_between_2d_vectors, 弄懂这个夹角公式。
- 然后我下午画了一下午的图？？？我真的，不动脑子的事我是真喜欢干啊。
## 今日任务
- 小论文创新点
  - 1、以瞬时步为最小单元的编码
    - 坐标
  - 2、基于多模态的轨迹解码
- 我突然发现创新点就是串改并，并改串
  - 串改并
    - 之前是基于(A,128)多次生成，组成多模态轨迹。
  - 并改串
    - 之前是轨迹一次全部生成，改成多段多次生成。
  - 我把别人的(A,6,128)改成(3,A,6,128)算是什么呢？
- 代码详解：以query为中心的解码
  - t2m
    - edge: Tensor(A,20,1) & Tensor(A,1,6) -> Tensor(A,20,6)
      - Tensor(A,20,1) 为bool类型，表示**该步历史轨迹是否存在**且是否在**时间半径**内。
      - Tensor(A,1,6) 为bool类型，表示该未来轨迹是否存在，由真值情况而定，不存在真值则为假。
    - r: 
      - 时间半径内的需学习步与**最后已知位置**之间的**距离**。
      - 视角切换到最后已知位置，临近步的方位。
      - 航向差。
      - 时间差
  - pl2m
    - edge: polygon与最后已知位置在**地图半径**内则存在边
    - r: 
      - 最后已知位置到polygon的距离
      - 最后已知位置到polygon的方位
      - 航向差
  - a2m
    - edge: 两Agent最后已知位置距离在**Agent半径**内则存在边，有向边，相互指向
    - r: 
      - 两车距离
      - 两车方位
      - 两车航向差
- 解码器的思考
  - 所以需要写的点就是，如果不通过每个场景计算每辆他车，每个路点的相对位置，如何还原出相对的位置。其实，不也是需要计算吗。可能时间复杂度不一样？
  - 以最后已知位置求edge。之前的代码我写出来没办法收敛。
  - 以query为中心就是以mode为中心，也就是以最后已知位置为中心。
  - 将time、polygon和其他Agent编入m一次，解码出来是0-1秒，编入两次就是1-2秒，三次是2-3秒，这其实是扯淡，有逻辑漏洞。
  - 当然，我也不知道是不是m循环的越多效果越好。
  - 我先全部解码，对应 (A,6,30,2)，得到的m是(A,6,10,2)通过GRU编码的(A,6,128)，这样的话就没有逻辑漏洞。m的循环次数也就少了。
- 粗预测部分的思考
  - 最开始m的维度(A,6,128)，我可以直接选择最后已知位置然后扩充，这也是QCNet做的。
  - 但我又比较想加一个GRU，将(A,20,128)卷成(A,1,128)然后扩充，这样表达的意思其实是以Agent为中心，而不是以最后已知步为中心。
  - 当然，这样的话就跟QCNet想表达的意思有出入了，因为总得选择一个点来构建图关系。
  - 那我如果先以Agent为中心来进行粗预测，然后再以粗预测编码为核心呢？
  - 那就是我粗预测的cross-attention的逻辑也得修改？
  - ========================
  - 还是仔细想了想，以最后已知位置为代表，然后把时间、临车、临道全部编进去，不也是一样的吗？
  - 如果是为了区别的话，那确实可以多做一步。相当于把时间维度先编码了，后面只编码空间维度。

# 2023.12.20 周三
## 总结
- 上午有点想摆了。
- 下午必须得工作了！
  - 初始2841个字。结束4000字。
  - 我突然想到一个恐怖的情况，毕业论文需要三万字以上，后面要删的话最好写到4万字。每天写一千字都得写40天！我以为一天写一千字已经很牛了，但其实这才到勉强完成的程度？
- [ ] 消融实验：为什么是总体预测然后分段优化，不能直接分段预测吗？
  - 分段预测然后整体优化那就是QCNet了。
  - 有一个解释：由于我的优化是基于2秒优化1秒，需要已经预测出来的值作为参考，所以不能直接分段预测。
- [ ] 优化过程中的**滑动窗口**
  - 理应是基于过去2秒预测1秒对吧，所以预测出来的值应该立即使用。就是E啊r啊都得再琢磨。在这**时间半径**就可以很合理的加进去了！
  - 这个代码得改，但不是现在。
- [ ] 多模态数大于6
- [ ] 旋转平移
  - QCNet预测的时候都是以最后已知位置为中心进行预测的，那我如果分段预测，岂不是得换坐标系？
  - 以最后已知位置为中心进行预测，所以预测出来的值再编码，相当于得再把预处理的过程再走一次。
- [x] agent编码与map编码部分的drawio我画好了
  - 总结就是Agent编码是以每步为中心的。
  - 而解码部分，是以模态为中心的。
- [x] 创建了q5_1
  - 用来写解码阶段的完整预测阶段。
- [ ] 创建了q5_2
  - 用来写解码阶段的优化轨迹阶段。
## 今日
- 还是得造词
  - 以Agent为基本单元(A,128)，以Agent多模态为中心(A*6,128)，以每步为中心(A*20,128)。
  - (A,6,30,2) <- (A,6,60) <- (A,6,128) <- (A*6,128)
- 还有就是编解码这种词汇实在是太奇怪了。
  - 我对Agent和Map编码的过程叫编码，我对query学习Agent和Map的过程就叫解码？
  - 不对吧，这同样是编码的过程。
  - 所以我得想办法造词啊，Agent编码，Map编码，交互编码，融合编码等等。
- 模态数不一定非得是6
  - 像是TNT，他也没老老实实只预测6个点啊，我完全可以多创建几个模态然后评分得到最好的模态最后输出。
- 造词：在分段预测里面，需要一个类似最后已知位置的概念。

# 2023.12.21 周四
## 总结
- 写了轨迹预测问题定义，数据集介绍写了总体和地图，还剩轨迹数据没写。
- 初始4000字，结束5180字
- 高铭今天就回家了，中午吃了个饭。
- 晚上看了会吉他课，创了个新 node：guitar.md。

# 2023.12.22 周五
## 总结
- 初始5180字，上午结束5608，写完了数据集介绍。
- 下午写分段修正与损失函数：
- 下午结束5730。画图和想模型结构去了。应该是最后一个点想清楚了，也就是对 x_a 再编码。
## 今日
- 再编码与分段修正
  - 如果历史轨迹不全为已知的话，需要对x_a再编码，这里原有的x_a就是直接emb出来的
  - 1、需要复用Agent编码中的 x_a_emb 吗？
  - 2、起码有两段再编码，如果不复用，那再新建两个 x_a_emb 吗？

############################# 第四周 ###################################
# 2023.12.25 周一
## 本周
- [ ] 1、结束大论文第一部分。
- [x] 2、修改分阶段轨迹预测代码。
- [ ] 3、阅读psq的大小论文及参考文献。
- [x] 4、准备元旦的黄梅之旅。
  - [x] 打电话家里
  - [x] 剪头
  - [x] 节食
  - [ ] 准备水果、排骨、丸子

## 总结
- 连吃了三天炒米粉，感觉有点消化不良了，真得控制每顿进食量。
- 叫了十年海光，今天才看到海。
- [x] 把Q5_2_mec写好了
  - 这模型算是完整体了，就看能不能收敛
## 今日
- 有三种坐标
  - 1、预测出来的每步位移, pace
  - 2、对每步位移进行 cumsum, 也就是以本Agent为中心的坐标, self
  - 3、全局坐标系下坐标, position

# 2023.12.26 周二
## 总结
- Q5_2_mec
  - 发现**refine部分无法收敛**
  - 打算只基于refine部分调参，所以就把**propose注释掉了**
  - 看能不能让**滑动窗口的代码收敛**。
  - 首先就是把模型扩大，每次解码十步，是不是该区分。不行
  - 每段用不同loss监督。
    - 分段算loss跟总体算有什么区别啊
    - 关于 **loss_pi**
  - 第一段与后两段最大的区别: ！！！
    - 开始预测出来的值不靠谱，所以要不要第一个epoch就训练第一段预测。
    - 需要把模型预热一下。
  - 结论
    - 用 **detach()** 将关联切断
    - 我还看见 with torch.no_grad(): 的形式
- 创建 Q5_3_mec, 用于将完整预测与轨迹修正结合，并改写pi
## 今日
- 打算上午改代码，下午写论文。
- 代码的问题解决了，确实可以按照我的想法写。

# 2023.12.27 周三
## 总结
- 上午把 ReNet 1.0 的代码写好，第一次开始跑，GPU利用率不是太高。
- 创建q5_4_mec，用于进一步优化代码。
- 下午完成大论文第一部分。最后是玩了一下午一晚上。
## 今日
- 损失函数
- 模型总结

# 2023.12.28 周四
## 总结
- 上午把轨迹再编码与分段修正修改一下，结果上午一块开了个会。
- 下午一上来在油管上看了两三个点的一拳人录播的校长，看的没意思才开始写大论文。
- 把大论文的轨迹优化写了一下，其中最复杂的update没写。
- q5_4_mec把rough与refine合一了。
## 今日
- 滑动窗口
  - 在整体预测中预测窗口为3s，基于2s预测3s，仅需一次预测。
  - 在轨迹修正中优化窗口为1s，基于2s历史与1s预测来得到对1s预测的优化值，每次优化完窗口向后滑动1s，故需要三次优化。每次使用的历史轨迹与环境都不同，所以需要重新编码。
- 轨迹再编码
  - 1、对预测轨迹再编码
    - 在轨迹优化中是基于整体预测值进行优化的，所以是future based。
  - 2、对历史轨迹再编码
    - 由于滑动窗口，故需要对历史轨迹再编码，edge和r需要再重新计算。
  - 3、层次
    - 1、更新：
      - 一级变量: history_mask, history_positions, history_heads, future_mask
      - 二级变量: last_position, last_head, rot_mat, last_head_cs, edge_index_m2m
      - 旋转平移: propose_self_section
      - 再编码历史轨迹: history_paces
      - edge_index_t, r_t,  ...
    - 2、图注意力: 
    - 3、解码: refine_positions, refine_scale, pi
- q5_4_mec
  - [x] 3代的代码里算了四次edge，其实可以简化为3次。
  - 创建q5_5_mec

# 2023.12.29 周五
## 总结
- 初始6031字。
## 今日
- 损失函数
  - QCNet论文中，称pi为混合系数(mixing coefficients), 一个不明所以的词。
  - loss_cls就是用于监督这个混合系数, 不优化position和scale, 仅优化pi